{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa1e99a5",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Coding Homework 6: [Your Name]\n",
    "\n",
    "Go through this notebook, following the instructions! \n",
    "\n",
    "- You can add new cells if you need (with the \\\"+\\\" button above); but, deleting cells could very likely cause your notebook to fail ***MarkUs*** autotesting (and you'd have to start over and re-enter your answers into a completely fresh version of the notebook to get things working again...).\n",
    "\n",
    "    - ***MarkUs*** autotesting works by running your notebook from top to bottom, and if there's an error when doing this (such as a variable is getting called that hasn't yet been defined, etc.) it can cause automated tests to fail; so, make sure your notebook runs from top to bottom without error once you're done (which you can do by restarting the \"Restart & Run All\" from the \"Kernel\" menu).\n",
    "\n",
    "> TAs will mark this assignment by first checking ***MarkUs*** autotests for completion and general correctness, and then manually reviewing your written response to `Q15` and `Q20` and quickly double checking for the presense of plotted figures for `Q2`, `Q17` and `Q18`.\n",
    "> - The  `Q0, Q2, Q4, Q15` and `Q16` questions \"automatically fail\" during automated testing so that ***MarkUs*** exposes example answers for student review and consideration for these problems: these failed ***MarkUs*** autotests\" are not counted against the student.\n",
    "# Coding Homework 6: [Your Name]\n",
    "\n",
    "Go through this notebook, following the instructions! \n",
    "\n",
    "- You can add new cells if you need (with the \\\"+\\\" button above); but, deleting cells could very likely cause your notebook to fail ***MarkUs*** autotesting (and you'd have to start over and re-enter your answers into a completely fresh version of the notebook to get things working again...).\n",
    "\n",
    "    - ***MarkUs*** autotesting works by running your notebook from top to bottom, and if there's an error when doing this (such as a variable is getting called that hasn't yet been defined, etc.) it can cause automated tests to fail; so, make sure your notebook runs from top to bottom without error once you're done (which you can do by restarting the \"Restart & Run All\" from the \"Kernel\" menu).\n",
    "\n",
    "> TAs will mark this assignment by first checking ***MarkUs*** autotests for completion and general correctness, and then manually reviewing your written response to `Q15` and `Q20` and quickly double checking for the presense of plotted figures for `Q2`, `Q17` and `Q18`.\n",
    "> - The  `Q0, Q2, Q4, Q15` questions \"automatically fail\" during automated testing so that ***MarkUs*** exposes example answers for student review and consideration for these problems: these failed ***MarkUs*** autotests\" are not counted against the student.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb0423",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Social Media and Anxiety\n",
    "\n",
    "There have been many questions regarding whether or not social media usage increases anxiety levels. For example, do  TikTok and Facebook posts create an unattainable sense of life success and satisfaction?  Does procrastinating by watching YouTube videos or reading Twitter posts contribute unnecessary stress from deadline pressure? A study was conducted to examine the relationship between social media usage and student anxiety. Students were asked to categorize their social media usage as \"High\" if it exceeded more than 2 hours per day, and then student anxiety levels where scored through as series of questions, with higher scores suggesting higher student anxiety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68cc11e2",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anxiety_scores</th>\n",
       "      <th>social_media_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.64</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.29</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.32</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.83</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.02</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33.31</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.60</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.13</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.69</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28.90</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26.43</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24.23</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.10</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32.86</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21.06</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28.89</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28.71</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31.73</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30.02</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21.96</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25.49</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>38.81</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27.85</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30.29</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30.72</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>21.43</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>22.24</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11.12</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30.86</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.92</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>33.57</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>34.09</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>27.63</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>31.26</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.91</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26.68</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>29.49</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>35.32</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>26.24</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>32.34</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>31.34</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>33.53</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>27.62</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>42.91</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>30.20</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>32.54</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    anxiety_scores social_media_usage\n",
       "0            24.64                Low\n",
       "1            39.29                Low\n",
       "2            16.32                Low\n",
       "3            32.83                Low\n",
       "4            28.02                Low\n",
       "5            33.31                Low\n",
       "6            20.60                Low\n",
       "7            21.13                Low\n",
       "8            26.69                Low\n",
       "9            28.90                Low\n",
       "10           26.43                Low\n",
       "11           24.23                Low\n",
       "12            7.10                Low\n",
       "13           32.86                Low\n",
       "14           21.06                Low\n",
       "15           28.89                Low\n",
       "16           28.71                Low\n",
       "17           31.73                Low\n",
       "18           30.02                Low\n",
       "19           21.96                Low\n",
       "20           25.49                Low\n",
       "21           38.81                Low\n",
       "22           27.85                Low\n",
       "23           30.29                Low\n",
       "24           30.72                Low\n",
       "25           21.43                Low\n",
       "26           22.24                Low\n",
       "27           11.12                Low\n",
       "28           30.86                Low\n",
       "29           19.92                Low\n",
       "30           33.57               High\n",
       "31           34.09               High\n",
       "32           27.63               High\n",
       "33           31.26               High\n",
       "34           35.91               High\n",
       "35           26.68               High\n",
       "36           29.49               High\n",
       "37           35.32               High\n",
       "38           26.24               High\n",
       "39           32.34               High\n",
       "40           31.34               High\n",
       "41           33.53               High\n",
       "42           27.62               High\n",
       "43           42.91               High\n",
       "44           30.20               High\n",
       "45           32.54               High"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "\n",
    "# The `numpy.repeat` function replicates elements as demonstrated here\n",
    "social_media_usage = np.repeat([\"Low\", \"High\"], [30, 16])\n",
    "anxiety_scores = [24.64, 39.29, 16.32, 32.83, 28.02, \n",
    "                   33.31, 20.60, 21.13, 26.69, 28.90,\n",
    "                   26.43, 24.23, 7.10,  32.86, 21.06,\n",
    "                   28.89, 28.71, 31.73, 30.02, 21.96,\n",
    "                   25.49, 38.81, 27.85, 30.29, 30.72,\n",
    "                   21.43, 22.24, 11.12, 30.86, 19.92,\n",
    "                   33.57, 34.09, 27.63, 31.26,\n",
    "                   35.91, 26.68, 29.49, 35.32,\n",
    "                   26.24, 32.34, 31.34, 33.53,\n",
    "                   27.62, 42.91, 30.20, 32.54]\n",
    "anxiety_data = pd.DataFrame({'anxiety_scores': anxiety_scores, 'social_media_usage': social_media_usage})\n",
    "anxiety_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7e5b9",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q0: In simple terms, what is the claim of the *null hypothesis* for the experiment above that we are naturally trying to provide evidence against? How could this be formally stated with respect to the parameters $Median_{High}$ and $Median_{Low}$ of the two populations in question? And what is $H_1$ in terms of $H_0$?\n",
    "\n",
    "#### Provide your written answer in the markdown cell below.\n",
    "\n",
    "> Hint: In two-sample contexts the *null hypotheses* tends to be the most natural form of a \"no effect\" statement that \"nothing interesting or notable is happening\"; and, it's generally a \"straw man\" that we're trying to provide enough evidence against to reject. For example, a formal *null hypotheses* that there is no difference in the means of two groups would be $H_0: \\mu_{High} = \\mu_{Low}$.\n",
    "\n",
    "- You can compare your answer with the example solution provided by MarkUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af87b2b",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b09d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\nIncluded as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += \"The natural null hypothesis here is that social media usage does not affect stress, \\n\"\n",
    "hint += \"because this is the idea (null hypothesis) we'd like to provide evidence against. \\n\"\n",
    "hint += \"Formally, for \\\"High\\\" social media usage population H \\nand \\\"Low\\\" social media usage population L with medians \\n\"\n",
    "hint += \"$\\\\text{50\\%}_{\\\\text{H}}$ and $\\\\text{50\\%}_{\\\\text{L}}$, respectively, \\n\"\n",
    "hint += \"the null and alternative hypothesis in $\\\\LaTeX$ are\\n\"\n",
    "hint += '''\n",
    "$\n",
    "H_0: \\\\text{50\\%}_{\\\\text{H}} = \\\\text{50\\%}_{\\\\text{L}} \\\\\\\\\n",
    "H_1: H_0 \\\\text{ is false } (\\\\text{50\\%}_{\\\\text{H}} \\\\neq \\\\text{50\\%}_{\\\\text{L}})\n",
    "$\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b68ab7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nThe natural null hypothesis here is that social media usage does not affect stress, \nbecause this is the idea (null hypothesis) we'd like to provide evidence against. \nFormally, for \"High\" social media usage population H \nand \"Low\" social media usage population L with medians \n$\\text{50\\%}_{\\text{H}}$ and $\\text{50\\%}_{\\text{L}}$, respectively, \nthe null and alternative hypothesis in LaTeX are\n\n$\nH_0: \\text{50\\%}_{\\text{H}} = \\text{50\\%}_{\\text{L}} \\\\\nH_1: H_0 \\text{ is false } (\\text{50\\%}_{\\text{H}} \\neq \\text{50\\%}_{\\text{L}})\n$\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q0\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: \n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nThe natural null hypothesis here is that social media usage does not affect stress, \nbecause this is the idea (null hypothesis) we'd like to provide evidence against. \nFormally, for \"High\" social media usage population H \nand \"Low\" social media usage population L with medians \n$\\text{50\\%}_{\\text{H}}$ and $\\text{50\\%}_{\\text{L}}$, respectively, \nthe null and alternative hypothesis in LaTeX are\n\n$\nH_0: \\text{50\\%}_{\\text{H}} = \\text{50\\%}_{\\text{L}} \\\\\nH_1: H_0 \\text{ is false } (\\text{50\\%}_{\\text{H}} \\neq \\text{50\\%}_{\\text{L}})\n$\n"
     ]
    }
   ],
   "source": [
    "# test_Q0\n",
    "assert False, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf8950",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q1: Revisit your statements regarding the *null hypotheses* above with \"confounding\" in mind; namely, since social media usage is a self-selecting process, perhaps social media users are already more anxious people on average regardless of their social media usage.  If we provide evidence about the *null hypotheses* are we actually addressing the question of \"whether or not usage of social media increases anxiety levels\"? Or are we just using a hypothesis test to examine if there is strong evidence of difference between the two groups (regardless of its causes)?  \n",
    "\n",
    "A. Neither, we are checking if confounding impacts our determination of \"whether or not usage of social media increases anxiety levels\"  \n",
    "\n",
    "B. We actually addressing the question of \"whether or not usage of social media increases anxiety levels\"   \n",
    "\n",
    "C. We are just using a hypothesis test to examine how strong the observable evidence of a difference between the two groups is (regardless of its causes)  \n",
    "\n",
    "D. None of the above: we cannot determine any of the above from a two-sample hypothesis test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef4a6a6",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q1: your answer will be tested!\n",
    "Q1 = None # Assign either 'A' or 'B' or 'C' or 'D' to `Q1` instead of `None`\n",
    "# E.g., Q1 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0c8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"The null hypothesis is a statement of equivalence between the two groups,\\n\"\n",
    "hint += \"so a two-sample hypothesis might be able to provide evidence against the null hypothesis\\n\"\n",
    "hint += \"on the basis of an observable strong difference between the two groups, or fail to do so. \\n\"\n",
    "hint += \"The null hypothesis tells us nothing about any cause of a possible difference; however...\\n\\n\"\n",
    "hint += \"if we don't think there is any confounding, then the difference would be attributable to\\n\"\n",
    "hint += \"the remaining differences between the two groups... which here would be social media usage...\\n\\n\"\n",
    "hint += \"Confounding of pre-existing differences between the two groups does seem like it might be\\n\"\n",
    "hint += \"possible, so that might explain differences; or, social media usage may indeed be what's\\n\"\n",
    "hint += \"really different between the two groups after all...\"\n",
    "\n",
    "test = Q1 == 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d64b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The null hypothesis is a statement of equivalence between the two groups,\nso a two-sample hypothesis might be able to provide evidence against the null hypothesis\non the basis of an observable strong difference between the two groups, or fail to do so. \nThe null hypothesis tells us nothing about any cause of a possible difference; however...\n\nif we don't think there is any confounding, then the difference would be attributable to\nthe remaining differences between the two groups...\n\nConfounding of pre-existing differences between the two groups does seem like it might be\npossible, so that might explain differences; or, social media usage may indeed be what's\nreally different between the two groups after all...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test_Q1\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test, hint\n",
      "\u001b[0;31mAssertionError\u001b[0m: The null hypothesis is a statement of equivalence between the two groups,\nso a two-sample hypothesis might be able to provide evidence against the null hypothesis\non the basis of an observable strong difference between the two groups, or fail to do so. \nThe null hypothesis tells us nothing about any cause of a possible difference; however...\n\nif we don't think there is any confounding, then the difference would be attributable to\nthe remaining differences between the two groups...\n\nConfounding of pre-existing differences between the two groups does seem like it might be\npossible, so that might explain differences; or, social media usage may indeed be what's\nreally different between the two groups after all..."
     ]
    }
   ],
   "source": [
    "# test_Q1\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6a5b2",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q2: Construct boxplots of `anxiety_data.anxiety_scores` for the two levels of social media usage, and write 2-3 sentences describing and comparing the distributions of anxiety scores across the social media usage groups.  \n",
    "#### Provide your `plotly` boxplot figure and written answer in the code and markdown cells below, respectively.\n",
    "\n",
    "> Hint: this is very easy to do with the `x` and `y` parameters of the the `px.box` function...\n",
    "\n",
    "- You can compare your answer with the example solution provided by MarkUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e8211ff",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Code your solution here\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae8370",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f0e7af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\n\"\n",
    "hint += \"Included as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += \"CODE:\\n\"\n",
    "hint += '''\n",
    "import plotly.express as px\n",
    "fig = px.box(anxiety_data, x='anxiety_scores', y = 'social_media_usage')\n",
    "fig.show()\n",
    "'''\n",
    "hint += \"\\n\\nWRITTEN SOLUTION:\\n\\n\"\n",
    "hint += \"A simple statement of the visual appearance of the comparison of the two groups\\n\" \n",
    "hint += \"is that they both appear to be roughtly symmetric, with the \\\"High\\\" group both\\n\"\n",
    "hint += \"shifted up to the right with higher scores and simultaneously more tightly\\n\"\n",
    "hint += \"centered around a higher average score compared to the \\\"Low\\\" group whose wider\\n\"\n",
    "hint += \"spread that extends both higher as well as quite a bit below the \\\"High\\\" group.\\n\\n\"\n",
    "hint += \"To give a little more detail...\\n\"\n",
    "hint += \"there indeed appears to be a clear difference in anxiety between \\\"Low\\\" and \\\"High\\\" \\n\"\n",
    "hint += \"social media usage groups, with the median of the \\\"High\\\" group exceeding the 75th \\n\"\n",
    "hint += \"percentile of the \\\"Low\\\" group.  For the \\\"High\\\" social media usage group, \\n\"\n",
    "hint += \"the anxiety scores are much more concentrated around high (>30) anxiety scores \\n\"\n",
    "hint += \"with a tighter spread; whereas, for the \\\"Low\\\" social media usage group, \\n\"\n",
    "hint += \"the anxiety scores are much more highly variable, with the upper 50% of the \\n\"\n",
    "hint += \"anxiety scores in the \\\"Low\\\" social media usage group overlapping or even \\n\"\n",
    "hint += \"exceeding some scores in the \\\"High\\\" social media usage group, but most \\n\"\n",
    "hint += \"of the lower 50% of anxiety scores in the \\\"Low\\\" social media usage group \\n\"\n",
    "hint += \"being less than all the scores in the \\\"High\\\" social media usage group.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce3022e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nCODE:\n\nimport plotly.express as px\nfig = px.box(anxiety_data, x='anxiety_scores', y = 'social_media_usage')\nfig.show()\n\n\nWRITTEN SOLUTION:\n\nA simple statement of the visual appearance of the comparison of the two groups\nis that they both appear to be roughtly symmetric, with the \"High\" group both\nshifted up to the right with higher scores and simultaneously more tightly\ncentered around a higher average score compared to the \"Low\" group whose wider\nspread that extends both higher as well as quite a bit below the \"High\" group.\n\nTo give a little more detail...\nthere indeed appears to be a clear difference in anxiety between \"Low\" and \"High\" \nsocial media usage groups, with the median of the \"High\" group exceeding the 75th \npercentile of the \"Low\" group.  For the \"High\" social media usage group, \nthe anxiety scores are much more concentrated around high (>30) anxiety scores \nwith a tighter spread; whereas, for the \"Low\" social media usage group, \nthe anxiety scores are much more highly variable, with the upper 50% of the \nanxiety scores in the \"Low\" social media usage group overlapping or even \nexceeding some scores in the \"High\" social media usage group, but most \nof the lower 50% of anxiety scores in the \"Low\" social media usage group \nbeing less than all the scores in the \"High\" social media usage group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test_Q2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, hint\n",
      "\u001b[0;31mAssertionError\u001b[0m: \n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nCODE:\n\nimport plotly.express as px\nfig = px.box(anxiety_data, x='anxiety_scores', y = 'social_media_usage')\nfig.show()\n\n\nWRITTEN SOLUTION:\n\nA simple statement of the visual appearance of the comparison of the two groups\nis that they both appear to be roughtly symmetric, with the \"High\" group both\nshifted up to the right with higher scores and simultaneously more tightly\ncentered around a higher average score compared to the \"Low\" group whose wider\nspread that extends both higher as well as quite a bit below the \"High\" group.\n\nTo give a little more detail...\nthere indeed appears to be a clear difference in anxiety between \"Low\" and \"High\" \nsocial media usage groups, with the median of the \"High\" group exceeding the 75th \npercentile of the \"Low\" group.  For the \"High\" social media usage group, \nthe anxiety scores are much more concentrated around high (>30) anxiety scores \nwith a tighter spread; whereas, for the \"Low\" social media usage group, \nthe anxiety scores are much more highly variable, with the upper 50% of the \nanxiety scores in the \"Low\" social media usage group overlapping or even \nexceeding some scores in the \"High\" social media usage group, but most \nof the lower 50% of anxiety scores in the \"Low\" social media usage group \nbeing less than all the scores in the \"High\" social media usage group."
     ]
    }
   ],
   "source": [
    "# test_Q2\n",
    "assert False, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d71493",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q3: What do these data visually suggest regarding the claim that the ***median*** anxiety level is different for the population of people with high frequency social media use compared to the population with low frequency use? \n",
    "\n",
    "A. The median anxiety level is likely higher for low frequency social media users compared to higher frequency social media users.  \n",
    "\n",
    "B. We cannot say, since the groups are shuffled and we do not know the proportion of high frequency or lower frequency social media users in each group.    \n",
    "\n",
    "C. The median anxiety level is likely the same for low frequency social media users compared to higher frequency social media users.  \n",
    "\n",
    "D. The median anxiety level is likely higher for high frequency social media users compared to lower frequency social media users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21826f8b",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q3: your answer will be tested!\n",
    "Q3 = None # Assign either 'A' or 'B' or 'C' or 'D' to `Q3` instead of `None`\n",
    "# E.g., Q3 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c910ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"On each box in the boxplot, the left side is the 25th percentile, \\n\"\n",
    "hint += \"the middle line is the 50th percentile while the right side is the 75th percentile.\\n\"\n",
    "hint += \"Consider reviewing the answer to Q2 if this hint is not sufficiently helpful.\"\n",
    "test = Q3 == 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08440bdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "On each box in the boxplot, the left side is the 25th percentile, \nthe middle line is the 50th percentile while the right side is the 75th percentile.\nConsider reviewing the answer to Q2 if this is not sufficiently helpful.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test_Q3\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test, hint\n",
      "\u001b[0;31mAssertionError\u001b[0m: On each box in the boxplot, the left side is the 25th percentile, \nthe middle line is the 50th percentile while the right side is the 75th percentile.\nConsider reviewing the answer to Q2 if this is not sufficiently helpful."
     ]
    }
   ],
   "source": [
    "# test_Q3\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c551c2",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q4: Write a few sentences explaining what the code inside the `for` loop below does and why it's doing it.  \n",
    "#### Provide your written answer in the markdown cell below.\n",
    "- You can compare your answer with the example solution provided by MarkUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08324cb1",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ce3fa41",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "Difference in Medians=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "grey",
          "line": {
           "color": "black",
           "width": 1
          },
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          3.9299999999999997,
          -1.1700000000000017,
          2.960000000000001,
          2.129999999999999,
          -1.6599999999999966,
          -0.8299999999999983,
          -0.125,
          0.7299999999999969,
          -3.5749999999999993,
          1.8099999999999952,
          1.0300000000000011,
          -3.5599999999999987,
          -0.3949999999999996,
          -3.490000000000002,
          0.22499999999999787,
          -0.7499999999999964,
          -1.9299999999999997,
          -0.4700000000000024,
          -2.594999999999999,
          0.9549999999999983,
          2.5199999999999996,
          -0.7299999999999969,
          2.914999999999999,
          2.174999999999997,
          -3.5599999999999987,
          -2.6199999999999974,
          -0.740000000000002,
          -1.0449999999999982,
          -1.7449999999999974,
          4.234999999999999,
          -1.5199999999999996,
          -1.7300000000000004,
          3.8199999999999967,
          0.740000000000002,
          -0.20500000000000185,
          -3.5549999999999997,
          0.8049999999999997,
          -1.3799999999999955,
          -1.8799999999999955,
          1.389999999999997,
          -3.125,
          3.219999999999999,
          2.309999999999995,
          -2.75,
          -2.219999999999999,
          1.4600000000000009,
          -1.3099999999999987,
          1.495000000000001,
          1.269999999999996,
          0.3949999999999996,
          3.424999999999997,
          -0.0400000000000027,
          2.3999999999999986,
          -1.389999999999997,
          -1.7000000000000028,
          0.20500000000000185,
          -3.049999999999997,
          1.6449999999999996,
          3.0899999999999963,
          0.8249999999999993,
          1.5249999999999986,
          2.174999999999997,
          0.22499999999999787,
          0.4499999999999993,
          1.5899999999999999,
          -1.9999999999999964,
          -2.309999999999995,
          -1.7449999999999974,
          -1.3550000000000004,
          -0.7299999999999969,
          -0.3949999999999996,
          -0.1750000000000007,
          3,
          -0.1750000000000007,
          -0.4700000000000024,
          1.8399999999999999,
          -1.6149999999999984,
          -2.1499999999999986,
          -4.0049999999999955,
          -0.9549999999999983,
          -2.854999999999997,
          -2.6199999999999974,
          1.7449999999999974,
          1.389999999999997,
          -1.0799999999999983,
          -2.094999999999999,
          -1.7899999999999991,
          1.7899999999999991,
          0.3949999999999996,
          -1.4799999999999969,
          -3.1700000000000017,
          0.8299999999999983,
          -1.8199999999999967,
          0.20500000000000185,
          -0.7499999999999964,
          1.9299999999999997,
          1.0249999999999986,
          -0.740000000000002,
          1.370000000000001,
          -2.0049999999999955,
          2.219999999999999,
          -0.9949999999999974,
          -0.9949999999999974,
          1.0949999999999989,
          0.5800000000000018,
          1.5249999999999986,
          0.5449999999999982,
          -1.4250000000000007,
          -0.0400000000000027,
          0.4700000000000024,
          1.8199999999999967,
          -1.3749999999999964,
          -2.174999999999997,
          -1.1799999999999962,
          -2.9450000000000003,
          1.5249999999999986,
          -2.094999999999999,
          1.0850000000000009,
          1.0949999999999989,
          -1.7899999999999991,
          -2.5699999999999967,
          2.289999999999999,
          2.6950000000000003,
          2.3699999999999974,
          1.8199999999999967,
          -3.3200000000000003,
          0.8249999999999993,
          -1.7899999999999991,
          1.2299999999999969,
          -0.20500000000000185,
          0.14000000000000057,
          2.6199999999999974,
          0.384999999999998,
          2.174999999999997,
          -0.7299999999999969,
          -1.0899999999999999,
          -2.5049999999999955,
          -2.764999999999997,
          -1.7749999999999986,
          -2.014999999999997,
          -2.364999999999995,
          -0.7299999999999969,
          2.375,
          -1.389999999999997,
          1.2949999999999946,
          2.4899999999999984,
          -3.5599999999999987,
          1.259999999999998,
          -0.14000000000000057,
          0.3949999999999996,
          1.8149999999999977,
          -0.21499999999999986,
          -2.094999999999999,
          2.8200000000000003,
          -1.3099999999999987,
          -0.3949999999999996,
          1.8199999999999967,
          4.454999999999998,
          2.599999999999998,
          2.2650000000000006,
          1.6149999999999949,
          0.384999999999998,
          2.7699999999999996,
          3.424999999999997,
          2.414999999999999,
          -1.1849999999999952,
          0.3949999999999996,
          1.370000000000001,
          3.0899999999999963,
          -1,
          1.9299999999999997,
          2.014999999999997,
          1.389999999999997,
          -0.5599999999999987,
          -2.1900000000000013,
          3.905000000000001,
          1.6099999999999994,
          3.8199999999999967,
          2.1949999999999967,
          2.129999999999999,
          -2.5249999999999986,
          0.20500000000000185,
          2.599999999999998,
          -1.894999999999996,
          -0.6600000000000001,
          1.7850000000000001,
          1.4799999999999969,
          0.4700000000000024,
          -2.5349999999999966,
          -1.0449999999999982,
          0.384999999999998,
          -1.9200000000000017,
          -2.285,
          -1.7549999999999955,
          0.125,
          -3.125,
          2.599999999999998,
          -1.259999999999998,
          -1.9849999999999994,
          -0.4700000000000024,
          -2.854999999999997,
          -0.6600000000000001,
          1.4949999999999974,
          1.389999999999997,
          1.389999999999997,
          3.5549999999999997,
          -0.0400000000000027,
          2.599999999999998,
          2.035,
          1.8199999999999967,
          1.259999999999998,
          3.1599999999999966,
          -2.719999999999999,
          -2.239999999999995,
          2.7449999999999974,
          -0.0400000000000027,
          -2.789999999999999,
          -3.1449999999999996,
          -0.20500000000000185,
          0.8299999999999983,
          2.0249999999999986,
          -2.965,
          -0.384999999999998,
          1.7249999999999979,
          1.9299999999999997,
          -0.6499999999999986,
          -1,
          2.394999999999996,
          0.9549999999999983,
          1.3000000000000007,
          -1.8099999999999987,
          -2.2099999999999973,
          -2.995000000000001,
          2.5049999999999955,
          2.6199999999999974,
          3.085000000000001,
          3.4800000000000004,
          2.0450000000000017,
          2.129999999999999,
          -2.139999999999997,
          -3.384999999999998,
          2.375,
          2.5049999999999955,
          -3.3200000000000003,
          2.1499999999999986,
          2.759999999999998,
          -0.8299999999999983,
          -1.6550000000000011,
          0.4049999999999976,
          1.4749999999999979,
          3.1999999999999993,
          1.9299999999999997,
          -1.5999999999999979,
          -0.8299999999999983,
          -0.125,
          -0.740000000000002,
          0.8299999999999983,
          2.5199999999999996,
          -2.0049999999999955,
          0.8249999999999993,
          -1.7749999999999986,
          0.07000000000000028,
          -0.3949999999999996,
          -1.4449999999999967,
          -0.3949999999999996,
          -1.9450000000000003,
          -0.5599999999999987,
          -0.8249999999999993,
          -3.4750000000000014,
          -3.125,
          0.8299999999999983,
          -1.3900000000000006,
          2.014999999999997,
          2.7449999999999974,
          0.3949999999999996,
          1.3000000000000007,
          -0.6600000000000001,
          -2.639999999999997,
          0.4700000000000024,
          -2.4099999999999966,
          -1.3099999999999987,
          -2.139999999999997,
          -3.25,
          0.9949999999999974,
          0.9549999999999983,
          2.419999999999998,
          -0.0400000000000027,
          -1.3900000000000006,
          1.375,
          -0.26000000000000156,
          2.174999999999997,
          3.349999999999998,
          -3.0899999999999963,
          1.0050000000000026,
          0.740000000000002,
          -0.20500000000000185,
          0.22499999999999787,
          -0.7949999999999982,
          -0.6499999999999986,
          -2.625,
          -1.0449999999999982,
          1.1799999999999962,
          0.8299999999999983,
          2.6149999999999984,
          0.14000000000000057,
          -1.3449999999999989,
          -0.125,
          2.129999999999999,
          3.5549999999999997,
          -1.8799999999999955,
          2.6199999999999974,
          0.8299999999999983,
          2.884999999999998,
          -2.639999999999997,
          -2.5049999999999955,
          -2.5049999999999955,
          -1.9749999999999979,
          -2.7349999999999994,
          1.9299999999999997,
          0.3949999999999996,
          -1.3449999999999989,
          2.330000000000002,
          -0.20500000000000185,
          0.3949999999999996,
          -4.765000000000001,
          -0.3949999999999996,
          0.384999999999998,
          -0.4700000000000024,
          0.20500000000000185,
          -0.20500000000000185,
          -3.4350000000000023,
          -4.344999999999999,
          1.4050000000000011,
          -2.164999999999999,
          2.3699999999999974,
          -0.3450000000000024,
          -2.3649999999999984,
          0.07000000000000028,
          -0.129999999999999,
          1.389999999999997,
          3.3550000000000004,
          -0.6999999999999993,
          3.289999999999999,
          2.3699999999999974,
          -2.6950000000000003,
          3.9099999999999966,
          1.9099999999999966,
          -2.014999999999997,
          -3.0299999999999976,
          1.9349999999999987,
          1.389999999999997,
          0.740000000000002,
          -2.879999999999999,
          1.2950000000000017,
          2.594999999999999,
          -2.780000000000001,
          1.2049999999999983,
          3.7799999999999976,
          -3.424999999999997,
          -1.7300000000000004,
          -0.6499999999999986,
          3.1899999999999977,
          -1.7749999999999986,
          -1.7449999999999974,
          1.9349999999999987,
          -2.5249999999999986,
          -1.1799999999999997,
          -0.3949999999999996,
          3.3049999999999997,
          -3.289999999999999,
          0.14000000000000057,
          0.4700000000000024,
          3.3550000000000004,
          1.5849999999999973,
          -0.47499999999999787,
          -0.6600000000000001,
          3.594999999999999,
          0.8149999999999977,
          -1.4749999999999979,
          -1.7399999999999949,
          -2.094999999999999,
          -0.9800000000000004,
          1.9099999999999966,
          0.33500000000000085,
          0.4700000000000024,
          -1.5249999999999986,
          -2.7349999999999994,
          -1.8299999999999983,
          1.4050000000000011,
          -2.75,
          -2.789999999999999,
          3.025000000000002,
          -1.0700000000000003,
          2.4849999999999994,
          2.3000000000000007,
          1.2950000000000017,
          -1.7199999999999989,
          -0.384999999999998,
          0.384999999999998,
          0.3949999999999996,
          -1.879999999999999,
          -2.6199999999999974,
          -0.14000000000000057,
          -0.7299999999999969,
          -0.21499999999999986,
          2.219999999999999,
          1.7299999999999969,
          0.9350000000000023,
          1.7199999999999989,
          0.5599999999999987,
          -2.854999999999997,
          -1.3099999999999987,
          3.7749999999999986,
          -0.14000000000000057,
          -0.129999999999999,
          0.8149999999999977,
          0.7299999999999969,
          -1.0799999999999983,
          -0.7949999999999982,
          0.6499999999999986,
          0.07000000000000028,
          -0.7499999999999964,
          -3.0549999999999997,
          1.625,
          2.719999999999999,
          -1.9849999999999994,
          -1.0799999999999983,
          0.5449999999999982,
          1.9699999999999989,
          1.2950000000000017,
          1.7449999999999974,
          -0.21499999999999986,
          -2.794999999999998,
          0.8299999999999983,
          -2.139999999999997,
          -1.4799999999999969,
          -1.8249999999999957,
          -0.384999999999998,
          -2.4099999999999966,
          -1.8199999999999967,
          -3.5599999999999987,
          -0.20500000000000185,
          -2.625,
          -2.710000000000001,
          3.164999999999999,
          3.219999999999999,
          3.294999999999998,
          -0.33500000000000085,
          -0.129999999999999,
          -3.754999999999999,
          1.389999999999997,
          2.7099999999999973,
          2.3049999999999997,
          -3.129999999999999,
          -2.0749999999999957,
          -3.134999999999998,
          -1.5649999999999977,
          0.740000000000002,
          1.2299999999999969,
          0.4499999999999993,
          -2.0749999999999957,
          1.0050000000000026,
          2.8149999999999977,
          -2.9499999999999993,
          0.3949999999999996,
          -1.4799999999999969,
          -2.285,
          2.759999999999998,
          -2.4849999999999994,
          -1.7899999999999991,
          2.6199999999999974,
          0.125,
          -2.1900000000000013,
          -3.164999999999999,
          -0.6499999999999986,
          -1.3099999999999987,
          -1.4799999999999969,
          -1.4449999999999967,
          0.14000000000000057,
          0.8299999999999983,
          1.0300000000000011,
          0.4700000000000024,
          -2.905000000000001,
          2.0199999999999996,
          -3.5549999999999997,
          -0.125,
          0.9149999999999991,
          0.8299999999999983,
          -1.4449999999999967,
          -2.9349999999999987,
          3.4349999999999987,
          -0.9149999999999991,
          0.22499999999999787,
          0.9549999999999983,
          -1.0449999999999982,
          -4.34,
          -3.164999999999999,
          -2.0650000000000013,
          -1.8299999999999983,
          -2.625,
          -0.20500000000000185,
          -1.5699999999999967,
          -2.9749999999999943,
          0.9249999999999972,
          -0.0400000000000027,
          -0.6050000000000004,
          1.0949999999999989,
          1.9299999999999997,
          0.20500000000000185,
          -2.995000000000001,
          2.6199999999999974,
          -0.6499999999999986,
          0.740000000000002,
          2.6050000000000004,
          -3.0549999999999997,
          3.6899999999999977,
          1.0899999999999999,
          0.740000000000002,
          -0.1750000000000007,
          1.5249999999999986,
          -1.6749999999999972,
          -1.8299999999999983,
          0.7299999999999969,
          -0.39000000000000057,
          -0.9549999999999983,
          -0.9949999999999974,
          3.349999999999998,
          0.8249999999999993,
          3.684999999999995,
          -3.905000000000001,
          0.6600000000000001,
          -1.6499999999999986,
          -1.8099999999999987,
          0.9149999999999991,
          1.3099999999999987,
          4.229999999999997,
          2.3699999999999974,
          1.8099999999999952,
          -2.509999999999998,
          1.9349999999999987,
          -2.8999999999999986,
          0.740000000000002,
          1.615000000000002,
          2.594999999999999,
          2.6199999999999974,
          -1.8799999999999955,
          -1.7049999999999983,
          2.5749999999999957,
          0.384999999999998,
          -3.789999999999999,
          0.9549999999999983,
          2.9549999999999983,
          -1.8799999999999955,
          -0.7949999999999982,
          2.1949999999999967,
          -1.3000000000000007,
          3.0699999999999967,
          1.9549999999999983,
          3.7749999999999986,
          -4.739999999999998,
          2.285,
          -0.6499999999999986,
          -4.645000000000003,
          0.740000000000002,
          0.14000000000000057,
          -1.0899999999999999,
          -1.7399999999999984,
          1.389999999999997,
          1.7399999999999984,
          -2.014999999999997,
          -0.27500000000000213,
          -0.7949999999999982,
          -1.0050000000000026,
          2.9800000000000004,
          2.3699999999999974,
          -2.285,
          0.4499999999999993,
          3.905000000000001,
          1.4749999999999979,
          1.259999999999998,
          2.724999999999998,
          -1.0799999999999983,
          1.0949999999999989,
          -2.120000000000001,
          1.875,
          -1.0850000000000009,
          2.594999999999999,
          2.6050000000000004,
          1.8199999999999967,
          0.8299999999999983,
          1.3099999999999987,
          3.1799999999999997,
          1.4600000000000009,
          0.7299999999999969,
          2.0199999999999996,
          0.3949999999999996,
          -1.8199999999999967,
          2.6149999999999984,
          2.759999999999998,
          -2.330000000000002,
          -0.7499999999999964,
          -2.854999999999997,
          1.6400000000000006,
          0.9949999999999974,
          -0.6600000000000001,
          -1,
          -1.0899999999999999,
          -1.8299999999999983,
          2.9549999999999983,
          0.125,
          2.4849999999999994,
          -1.0949999999999989,
          -1.3000000000000007,
          0.20500000000000185,
          0.384999999999998,
          1.384999999999998,
          3.469999999999999,
          2.4899999999999984,
          -2.764999999999997,
          2.155000000000001,
          0.8149999999999977,
          -3.2950000000000017,
          -0.3949999999999996,
          0.9549999999999983,
          -1.3049999999999962,
          -1.9299999999999997,
          0.7299999999999969,
          -1.4449999999999967,
          -1.0850000000000009,
          1.8299999999999983,
          0.9149999999999991,
          -3.25,
          -3.3649999999999984,
          2.4849999999999994,
          0.9249999999999972,
          2.719999999999999,
          -1.8749999999999964,
          -4.159999999999997,
          0.3949999999999996,
          -1.8799999999999955,
          -1.8500000000000014,
          -1.0449999999999982,
          1.0449999999999982,
          -2.5699999999999967,
          1.9099999999999966,
          2.0249999999999986,
          -2.6950000000000003,
          3.1999999999999993,
          2.960000000000001,
          -2.139999999999997,
          -4.844999999999999,
          -3.094999999999999,
          -0.8200000000000003,
          -0.6499999999999986,
          -2.6950000000000003,
          0.6600000000000001,
          0.9299999999999997,
          -1.3550000000000004,
          3.0849999999999973,
          1.1799999999999997,
          2.3699999999999974,
          -2.139999999999997,
          1.4100000000000001,
          -1.7449999999999974,
          0.384999999999998,
          -1.6300000000000026,
          2.6849999999999987,
          3.8999999999999986,
          -0.0400000000000027,
          -1.7349999999999959,
          -2.014999999999997,
          -2.6799999999999997,
          -1.9349999999999987,
          -1.5649999999999977,
          0.6600000000000001,
          -0.5599999999999987,
          1.0899999999999999,
          0.8299999999999983,
          -0.0400000000000027,
          -0.4700000000000024,
          -0.4700000000000024,
          -1.7449999999999974,
          3.9499999999999993,
          0.3949999999999996,
          -0.384999999999998,
          -1.4050000000000011,
          -0.7949999999999982,
          2.0199999999999996,
          -1.9699999999999989,
          1.370000000000001,
          -1.5249999999999986,
          -2.5,
          2.754999999999999,
          -0.6499999999999986,
          -0.8299999999999983,
          -2.224999999999998,
          0.6499999999999986,
          0.740000000000002,
          1.4799999999999969,
          1.6649999999999991,
          0.22499999999999787,
          -0.0400000000000027,
          2.414999999999999,
          -1.7300000000000004,
          2.0599999999999987,
          -0.6600000000000001,
          1.6749999999999972,
          1.4749999999999979,
          0.7299999999999969,
          4.014999999999997,
          3.5549999999999997,
          -2.224999999999998,
          -1.7449999999999974,
          -2.2099999999999973,
          -0.7850000000000001,
          2.864999999999995,
          1.3900000000000006,
          1.8000000000000007,
          -2.530000000000001,
          -1.3550000000000004,
          -1.3099999999999987,
          -1.3550000000000004,
          0.740000000000002,
          -0.9949999999999974,
          -0.3949999999999996,
          2.509999999999998,
          0.740000000000002,
          1.6749999999999972,
          -0.3949999999999996,
          2.364999999999995,
          -0.7499999999999964,
          -1.5899999999999999,
          -1.5399999999999991,
          5.725000000000001,
          4.975000000000001,
          1.5899999999999999,
          -4.015000000000004,
          -2.5049999999999955,
          1.259999999999998,
          3.4800000000000004,
          -2.014999999999997,
          0.9549999999999983,
          1.4749999999999979,
          -0.5599999999999987,
          -0.9549999999999983,
          0.3949999999999996,
          -2.835000000000001,
          0.9949999999999974,
          -0.7850000000000001,
          0.740000000000002,
          -0.4700000000000024,
          2.4849999999999994,
          -0.6499999999999986,
          1.875,
          -1.3550000000000004,
          -3.7349999999999994,
          2.0599999999999987,
          2.0799999999999983,
          -1.8799999999999955,
          2.0199999999999996,
          -1.3749999999999964,
          1.9249999999999972,
          -2.139999999999997,
          -3.25,
          2.424999999999997,
          2.7349999999999994,
          3.349999999999998,
          2.8399999999999963,
          -1.384999999999998,
          2.039999999999999,
          5.225000000000001,
          -0.9149999999999991,
          -1.7300000000000004,
          -0.740000000000002,
          0.8149999999999977,
          2.285,
          -3.25,
          -1.9549999999999983,
          1.0449999999999982,
          1.4749999999999979,
          2.6199999999999974,
          -0.26000000000000156,
          2.1099999999999994,
          -3.0549999999999997,
          2.4849999999999994,
          -0.20500000000000185,
          3.085000000000001,
          -3.1499999999999986,
          -1.1400000000000006,
          0.9350000000000023,
          1.8299999999999983,
          0.740000000000002,
          -2.164999999999999,
          2.0199999999999996,
          2.594999999999999,
          -0.20500000000000185,
          1.5899999999999999,
          0.20500000000000185,
          -3.164999999999999,
          2.9549999999999983,
          0.8299999999999983,
          3.349999999999998,
          -1.6300000000000026,
          0.4049999999999976,
          2.0199999999999996,
          2.960000000000001,
          -3.9400000000000013,
          1.375,
          -2.049999999999997,
          -1.3099999999999987,
          4.014999999999997,
          -2.8999999999999986,
          1.4799999999999969,
          1.0449999999999982,
          -2.75,
          2.594999999999999,
          0.384999999999998,
          -0.740000000000002,
          -3.269999999999996,
          -2.094999999999999,
          0.6499999999999986,
          -0.0400000000000027,
          -0.384999999999998,
          0.9549999999999983,
          3.0050000000000026,
          2.8249999999999993,
          5.135000000000002,
          2.0799999999999983,
          -0.21499999999999986,
          -0.06500000000000128,
          1.4799999999999969,
          -0.8200000000000003,
          0.22499999999999787,
          -0.14000000000000057,
          -2.594999999999999,
          -0.129999999999999,
          -0.3949999999999996,
          2.014999999999997,
          -2.094999999999999,
          -4.649999999999999,
          -1.0949999999999989,
          -0.6600000000000001,
          -3.405000000000001,
          2.7749999999999986,
          -0.14000000000000057,
          -1.0050000000000026,
          -1.2899999999999991,
          -0.740000000000002,
          -1.9649999999999963,
          -2.009999999999998,
          -1.5249999999999986,
          2.3999999999999986,
          -2.5249999999999986,
          0.8249999999999993,
          -2.309999999999995,
          -2.6199999999999974,
          0.9549999999999983,
          1.3099999999999987,
          3.4800000000000004,
          -1.3000000000000007,
          -2.5249999999999986,
          -1.4449999999999967,
          3.2049999999999983,
          -0.9549999999999983,
          3.424999999999997,
          2.484999999999996,
          0.120000000000001,
          -0.0400000000000027,
          2.174999999999997,
          0.7299999999999969,
          1.259999999999998,
          -2.219999999999999,
          -0.14000000000000057,
          -0.8299999999999983,
          0.3949999999999996,
          -1.0050000000000026,
          2.104999999999997,
          1.75,
          -0.9549999999999983,
          -1.9299999999999997,
          -1.6550000000000011,
          1.0449999999999982,
          -0.0400000000000027,
          -0.129999999999999,
          -1.4250000000000007,
          -0.6499999999999986,
          -0.6600000000000001,
          2.375,
          2.129999999999999,
          -1.3099999999999987,
          -5.350000000000001,
          -0.4700000000000024,
          -1.6550000000000011,
          -5.284999999999997,
          -1.8299999999999983,
          0.8299999999999983,
          -2.424999999999997,
          -3.5749999999999993,
          -0.8299999999999983,
          0.9299999999999997,
          -0.5599999999999987,
          -2.495000000000001,
          2.0599999999999987,
          -0.8149999999999977,
          0.4700000000000024,
          -1.0949999999999989,
          -1.0949999999999989,
          -1.375,
          1.375,
          1.4549999999999983,
          0.3949999999999996,
          3.0699999999999967,
          -3.0749999999999957,
          -1.6550000000000011,
          -1.3749999999999964,
          -4.344999999999999,
          -1.4449999999999967,
          -1.3550000000000004,
          -6.024999999999999,
          3.094999999999999,
          -0.20500000000000185,
          1.4600000000000009,
          -0.7499999999999964,
          -2.4049999999999976,
          0.9549999999999983,
          2.84,
          -1.389999999999997,
          0.8249999999999993,
          -0.125,
          1.8199999999999967,
          0.7499999999999964,
          0.8249999999999993,
          0.8049999999999997,
          -3.164999999999999,
          -2.6950000000000003,
          -3.4750000000000014,
          -1.8299999999999983,
          -2.1900000000000013,
          2.599999999999998,
          -0.7499999999999964,
          0.14000000000000057,
          -1.9699999999999989,
          3.289999999999999,
          -2.009999999999998,
          -1.8799999999999955,
          1.4799999999999969,
          0.4700000000000024,
          1.9399999999999977,
          -0.6499999999999986,
          1.5899999999999999,
          2.9549999999999983,
          -1.3449999999999989,
          3.0799999999999983,
          -2.7699999999999996,
          -0.6600000000000001,
          -1.5249999999999986,
          0.3949999999999996,
          1.259999999999998,
          4.549999999999997,
          -1.0449999999999982,
          0.9949999999999974,
          -1.0050000000000026,
          0.33999999999999986,
          -2.424999999999997,
          -1.6600000000000001,
          0.8249999999999993,
          -3.0549999999999997,
          -1.0799999999999983,
          1.129999999999999,
          3.6499999999999986,
          -1.9549999999999983,
          -0.9949999999999974,
          -0.5599999999999987,
          -0.6600000000000001,
          3.0849999999999973,
          -1.5649999999999977,
          2.6549999999999976,
          -2.309999999999995,
          2.174999999999997,
          2.754999999999999,
          3.8199999999999967,
          -0.7850000000000001,
          -0.6600000000000001,
          1.5700000000000003,
          -1.7049999999999983,
          0.33500000000000085,
          -0.20500000000000185,
          -0.14000000000000057,
          -0.384999999999998,
          -0.0400000000000027,
          -2.710000000000001,
          0.33500000000000085,
          -1.3550000000000004,
          -0.7850000000000001,
          -0.14000000000000057,
          -0.6050000000000004,
          1.384999999999998,
          2.174999999999997,
          -1.4799999999999969,
          -0.26000000000000156
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "red",
           "dash": "dash",
           "width": 3
          },
          "type": "line",
          "x0": -4.57,
          "x1": -4.57,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "red",
           "dash": "dash",
           "width": 3
          },
          "type": "line",
          "x0": 4.57,
          "x1": 4.57,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Difference in Medians"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.012"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_test_statistic = np.diff(anxiety_data.groupby('social_media_usage').median().values.flatten())\n",
    "\n",
    "np.random.seed(1) # make the simulation reproducible...\n",
    "repetitions = 5000 \n",
    "irrelevant_labels_null_hypothesis_simulated_values = []\n",
    "\n",
    "shuffled_anxiety_data = anxiety_data.copy() # you should essentially always use `.copy()` for data frames; otherwise,\n",
    "# changes to the new data frame will also appear in the original version of the data frame as well(!)\n",
    "\n",
    "for i in range(repetitions):\n",
    "    shuffled_anxiety_data['social_media_usage'] = anxiety_data['social_media_usage'].sample(frac=1).values\n",
    "    permutation_statistic = np.diff(shuffled_anxiety_data.groupby('social_media_usage').median().values.flatten())[0]\n",
    "    irrelevant_labels_null_hypothesis_simulated_values += [permutation_statistic]\n",
    "\n",
    "fig = px.histogram(pd.DataFrame({'Difference in Medians': irrelevant_labels_null_hypothesis_simulated_values}), \n",
    "                   x='Difference in Medians', color_discrete_sequence=['grey'], nbins=20)\n",
    "fig.update_traces(marker_line_width=1, marker_line_color=\"black\")\n",
    "fig.add_vline(x=observed_test_statistic[0], line_width=3, line_dash=\"dash\", line_color=\"red\")\n",
    "fig.add_vline(x=abs(observed_test_statistic[0]), line_width=3, line_dash=\"dash\", line_color=\"red\")\n",
    "fig.show()\n",
    "\n",
    "num_as_or_more_extreme = (abs(np.array(irrelevant_labels_null_hypothesis_simulated_values)) >= \n",
    "                          abs(observed_test_statistic)).sum()\n",
    "p_value = num_as_or_more_extreme / repetitions\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "075f45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\n\"\n",
    "hint += \"Included as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += \"The code overall produces a nonparametric permutation test p-value\\n\"\n",
    "hint += \"based on randomly shuffling the group labels under a (null hypothesis) assumption that they don't matter.\\n\\n\"\n",
    "hint += \"The first line of code in the `for` loop first shuffles the \\\"High\\\" and \\\"Low\\\" social media usage group labels\\n\"\n",
    "hint += \"for each observation. This implicitly assumes the outcomes for both groups are sampled from the same population\\n\"\n",
    "hint += \"(so that that actual group assignment label doesn't matter when estimating a population median from a sample),\\n\"\n",
    "hint += \"and that this population can be relatively reasonably 'represented' or 'estimated' based on the combined samples.\\n\"\n",
    "hint += \"This idea as a null hypothesis will thus be true for this simulated data (which treats the combined sample\\n\"\n",
    "hint += \"as the single population). So the subsequently calculated (median difference) statistic represents a draw from\\n\"\n",
    "hint += \"the sampling distribution of the median difference statistic under this null hypothesis assumption that it's\\n\"\n",
    "hint += \"calculated from two samples drawn from the same population (which thus have the same population median).\\n\"\n",
    "hint += \"Each repetition of the `for` loop allows us to repeatedly sample in this manner, creating the simulation\\n\"\n",
    "hint += \"of the sampling distribution of the median difference statistic under this null hypothesis assumption.\\n\\n\"\n",
    "hint += \"It's worth re-emphasizing that this is nonparametric since the two samples themselves are used to represent\\n\"\n",
    "hint += \"the population, and our analysis proceeds on the basis of that assumption. The more accurately the two\\n\"\n",
    "hint += \"samples actually represent the combined true populations, the more reliable the nonparametric analysis will be.\\n\"\n",
    "hint += \"Of course if the samples are wildly idiosyncratic and strange and thus don't well-represent their populations,\\n\"\n",
    "hint += \"then they'll make for 'unusual' statistical analysis results; but, this is true of any analysis that uses\\n\" \n",
    "hint += \"an 'unusual' sample that's just randomly 'strange' by the chance luck of the draw of the sample itself.\\n\\n\"\n",
    "hint += \"We will finally judge evidence against our null hypothesis by considering how 'strange' the observed test\\n\"\n",
    "hint += \"statistic is relative to the sampling distirbution based on assuming the 'one population' null hypothesis.\\n\"\n",
    "hint += \"If the observed test statistic doesn't seem like a reasonable possible sample from this sampling\\n\"\n",
    "hint += \"distribution (made based on assuming this null hypothesis) then the most sensible explanation would be\\n\"\n",
    "hint += \"that the assumption of the null hypothesis is likely not true!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ee26d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nThe code overall produces a nonparametric permutation test p-value\nbased on randomly shuffling the group labels under a (null hypothesis) assumption that they don't matter.\n\nThe first line of code in the `for` loop first shuffles the \"High\" and \"Low\" social media usage group labels\nfor each observation. This implicitly assumes the outcomes for both groups are sampled from the same population\n(so that that actual group assignment label doesn't matter when estimating a population median from a sample),\nand that this population can be relatively reasonably 'represented' or 'estimated' based on the combined samples.\nThis idea as a null hypothesis will thus be true for this simulated data (which treats the combined sample\nas the single population). So the subsequently calculated (median difference) statistic represents a draw from\nthe sampling distribution of the median difference statistic under this null hypothesis assumption that it's\ncalculated from two samples drawn from the same population (which thus have the same population median).\nEach repetition of the `for` loop allows us to repeatedly sample in this manner, creating the simulation\nof the sampling distribution of the median difference statistic under this null hypothesis assumption.\n\nIt's worth re-emphasizing that this is nonparametric since the two samples themselves are used to represent\nthe population, and our analysis proceeds on the basis of that assumption. The more accurately the two\nsamples actually represent the combined true populations, the more reliable the nonparametric analysis will be.\nOf course if the samples are wildly idiosyncratic and strange and thus don't well-represent their populations,\nthen they'll make for 'unusual' statistical analysis results; but, this is true of any analysis that uses\nan 'unusual' sample that's just randomly 'strange' by the chance luck of the draw of the sample itself.\n\nWe will finally judge evidence against our null hypothesis by considering how 'strange' the observed test\nstatistic is relative to the sampling distirbution based on assuming the 'one population' null hypothesis.\nIf the observed test statistic doesn't seem like a reasonable possible sample from this sampling\ndistribution (made based on assuming this null hypothesis) then the most sensible explanation would be\nthat the assumption of the null hypothesis is likely not true!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test_Q4\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, hint\n",
      "\u001b[0;31mAssertionError\u001b[0m: \n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nThe code overall produces a nonparametric permutation test p-value\nbased on randomly shuffling the group labels under a (null hypothesis) assumption that they don't matter.\n\nThe first line of code in the `for` loop first shuffles the \"High\" and \"Low\" social media usage group labels\nfor each observation. This implicitly assumes the outcomes for both groups are sampled from the same population\n(so that that actual group assignment label doesn't matter when estimating a population median from a sample),\nand that this population can be relatively reasonably 'represented' or 'estimated' based on the combined samples.\nThis idea as a null hypothesis will thus be true for this simulated data (which treats the combined sample\nas the single population). So the subsequently calculated (median difference) statistic represents a draw from\nthe sampling distribution of the median difference statistic under this null hypothesis assumption that it's\ncalculated from two samples drawn from the same population (which thus have the same population median).\nEach repetition of the `for` loop allows us to repeatedly sample in this manner, creating the simulation\nof the sampling distribution of the median difference statistic under this null hypothesis assumption.\n\nIt's worth re-emphasizing that this is nonparametric since the two samples themselves are used to represent\nthe population, and our analysis proceeds on the basis of that assumption. The more accurately the two\nsamples actually represent the combined true populations, the more reliable the nonparametric analysis will be.\nOf course if the samples are wildly idiosyncratic and strange and thus don't well-represent their populations,\nthen they'll make for 'unusual' statistical analysis results; but, this is true of any analysis that uses\nan 'unusual' sample that's just randomly 'strange' by the chance luck of the draw of the sample itself.\n\nWe will finally judge evidence against our null hypothesis by considering how 'strange' the observed test\nstatistic is relative to the sampling distirbution based on assuming the 'one population' null hypothesis.\nIf the observed test statistic doesn't seem like a reasonable possible sample from this sampling\ndistribution (made based on assuming this null hypothesis) then the most sensible explanation would be\nthat the assumption of the null hypothesis is likely not true!"
     ]
    }
   ],
   "source": [
    "# test_Q4\n",
    "assert False, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002c359",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q5: Which statement below best states the evidence you have against the *null hypothesis* based on the simulated p-value above?\n",
    "\n",
    "A. `0.10 < p-value`: No evidence against the null hypothesis  \n",
    "\n",
    "B. `0.05 < p-value <= 0.10`: Weak evidence against the null hypothesis  \n",
    "\n",
    "C. `0.01 < p-value <= 0.05`: Moderate evidence against the null hypothesis  \n",
    "\n",
    "D. `0.001 < p-value <= 0.01`: Strong evidence against the null hypothesis  \n",
    "\n",
    "E. `p-value < 0.001`: Very strong evidence against the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "678adfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: your answer will be tested!\n",
    "Q5 = None # Assign either 'A' or 'B' or 'C' or 'D' or 'E' to `Q5` instead of `None`\n",
    "# E.g., Q5 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da789e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"The null hypothesis assumes that there's no difference in the median anxiety \\n\"\n",
    "hint += \"level between the 'High' and 'Low' frequency social media usage populations in question.\\n\"\n",
    "hint += \"The p-value of 0.012 represents MODERATE evidence against the null hypothesis that the \\n\"\n",
    "hint += \"median anxiety level among \\\"High\\\" and \\\"Low\\\" social media usage groups is the same.\\n\\n\"\n",
    "hint += \"Further, the observed difference indicates that individuals with \\\"High\\\" social media usage\\n\"\n",
    "hint += \"have MORE anxiety than individuals with \\\"Low\\\" social media usage; however, if we reject the\\n\"\n",
    "hint += \"null hypothesis in favor of the alternative hypothesis, all that we are \\\"formally\\\" claiming \\n\"\n",
    "hint += \"is that the groups have different medians (and not necessarily which is larger...).\"\n",
    "test = Q5 == 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae89599",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The null hypothesis assumes that there's no difference in the median anxiety \nlevel between the 'High' and 'Low' frequency social media usage populations in question.\nThe p-value of 0.012 represents MODERATE evidence against the null hypothesis that the \nmedian anxiety level among \"High\" and \"Low\" social media usage groups is the same.\n\nFurther, the observed difference indicates that individuals with \"High\" social media usage\nhave MORE anxiety than individuals with \"Low\" social media usage; however, if we reject the\nnull hypothesis in favor of the alternative hypothesis, all that we are \"formally\" claiming \nis that the groups have different medians (and not necessarily which is larger...).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test_Q5\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test, hint\n",
      "\u001b[0;31mAssertionError\u001b[0m: The null hypothesis assumes that there's no difference in the median anxiety \nlevel between the 'High' and 'Low' frequency social media usage populations in question.\nThe p-value of 0.012 represents MODERATE evidence against the null hypothesis that the \nmedian anxiety level among \"High\" and \"Low\" social media usage groups is the same.\n\nFurther, the observed difference indicates that individuals with \"High\" social media usage\nhave MORE anxiety than individuals with \"Low\" social media usage; however, if we reject the\nnull hypothesis in favor of the alternative hypothesis, all that we are \"formally\" claiming \nis that the groups have different medians (and not necessarily which is larger...)."
     ]
    }
   ],
   "source": [
    "# test_Q5\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abcc58f",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q6: Does this data support the claim that the ***median*** anxiety level is different for those who use social media in high frequency compared to those who use social media in lower frequency?  How about the claim that \"usage of social media increases anxiety levels\"?\n",
    "\n",
    "A. Yes to the first, and yes to the second... there is a difference in median anxiety levels for those who use social media in high frequency compared to those who use social media in lower frequency, and it is because social media increases anxiety levels\n",
    "\n",
    "B. Yes to the first; but, no to the second... it seems possible -- not saying it's true, just plausible -- that different predispositions to anxiety could also have different predispositions to social media usage.  \n",
    "\n",
    "C. No to the first, and no to the second... this data does not adequately support the claim that the median anxiety level is different for those who use social media in high frequency compared to those who use social media in lower frequency  \n",
    "\n",
    "D. No to the first; but, yes to the second... the claim that the median anxiety level is different for those who use social media in high frequency compared to those who use social media in lower frequency is not supported, but we know usage of social media increases anxiety levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5363f3f8",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q6: your answer will be tested!\n",
    "Q6 = None # Assign either 'A' or 'B' or 'C' or 'D' to `Q6` instead of `None`\n",
    "# E.g., Q6 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f3410d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"Note that the first part of the question is the null hypothesis,\\n\"\n",
    "hint += \"so the data is how we may be able to provide evidence against the null hypothesis.\\n\"\n",
    "hint += \"Does the null hypothesis say anything about the cause of difference between median\\n\"\n",
    "hint += \"anxiety levels?  This is a question of of potential counfounding... that is, pre-\\n\"\n",
    "hint += \"existing differences between the two experimental groups we don't really know about...\"\n",
    "test = Q6 == 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8afa0568",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Note that the first part of the question is the null hypothesis,\nso the data is how we may be able to provide evidence against the null hypothesis.\nDoes the null hypothesis say anything about the cause of difference between median\nanxiety levels?  This is a question of of potential counfounding... that is, pre-\nexisting differences between the two experimental groups we don't really know about...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q6\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: Note that the first part of the question is the null hypothesis,\nso the data is how we may be able to provide evidence against the null hypothesis.\nDoes the null hypothesis say anything about the cause of difference between median\nanxiety levels?  This is a question of of potential counfounding... that is, pre-\nexisting differences between the two experimental groups we don't really know about..."
     ]
    }
   ],
   "source": [
    "# test_Q6\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a7066",
   "metadata": {},
   "source": [
    "### Q7: Use `scipy.stats.median_test` to calculate a p-value which could be used to provide evidence of a difference between the two social media usage groups.\n",
    "\n",
    "#### Provide your answer rounded to 3 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dabc6d",
   "metadata": {},
   "source": [
    "> - Hint 1: The \"median test\" produces a nonparametric p-value under the null hypothesis assumption that the median of two populations (here median anxiety levels of \"High\" and \"Low\" social media usage populations) are the same.\n",
    "> \n",
    ">   ```python\n",
    "> from scipy import stats \n",
    "> stats.median_test(series_A, series_B)\n",
    "> # where `series_A` and `series_B` are your two samples\n",
    "> ```\n",
    ">    - Boolean selection `anxiety_data.anxiety_scores[anxiety_data.social_media_usage=='Low']` could be useful...\n",
    ">\n",
    ">\n",
    "> - Hint 2: A test is nonparametric when it does not make specific distributional assumptions (such as normality) regarding the populations the samples come from; however, making assumptions about specific parameters of a population alone, such assuming something about the medians of two populations, does not make a test parametric. The terminology used here is somewhat unfortunate as it might make the difference between \"parametric\" and \"nonparametric\" a little more confusing than it needs to be...\n",
    ">\n",
    ">\n",
    "> - Hint 3: Use the `numpy.round` function to round your calculation.\n",
    ">\n",
    ">\n",
    "> - Hint 4: The \"median test\" is nonparametric just like the \"permutation shuffling test\" p-value simulated above; however, they are not quite the same test because they are based on slightly different assumptions: the null hypothesis assumptions the two (\"permutation shuffling test\" and \"median test\") testing methodologies are slighly different. \n",
    ">   - Shuffling the labels assumes that the labels don't matter, which implies that there's no difference between the populations the two samples come from; which, is a very strong statement null hypothesis (and we generally might expect stronger assumptions to be helpful in producing slightly small p-values...).\n",
    ">   - The \"median test\" instead is just based on assuming that if the medians of the two populations are the the same, then the null hypothesis is that half of the observations in the first group will be larger than half of the observations in the second group, and vice-versa; which, can be used to contruct another hypothesis test based on the Binomial distribution in a manner that is very much analagously to how such a Binomial test was created for a one-sample context...\n",
    ">     - Since the assumption of the \"median test\" is a little simpler and weaker than assuming two populations are identical and their samples interchangable, we'd expect p-values from a \"median test\" to be a little larger than p-values from a test based on a null hypothesis with slightly stronger assumptions...\n",
    ">     - Nonparametric p-values tend be a little bit larger than their parametric counterparts exactly because nonparametric null hypotheses tend to make fewer assumptions regarding the populations they're testing than their parametric counterparts which are derived on the basis of specific distributional assumptions about the populations that the samples being analyzed are drawn from.\n",
    ">\n",
    ">\n",
    "> - Hint 5: Another difference between the \"median test\" and the \"permutation shuffling test\" is that the former is theoretically derived, whereas the latter is based on a simulation.\n",
    ">    - Both parametric and nonparametric tests give p-values that are theoretically derived, as opposed to simulation based tests like the \"permutation shuffling test\" which use simulation to just simulate how things actually behave in order to give approximate p-values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49c9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# space for your work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90dd38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: your answer will be tested!\n",
    "Q7 = None # Assign p-value rounded to 3 decimal places to Q7 instead of 'None'\n",
    "# E.g., Q7 = '0.987'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ab447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcdfab35",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Got None for p-value but should be 0.03",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m p_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(stats\u001b[38;5;241m.\u001b[39mmedian_test(anxiety_data\u001b[38;5;241m.\u001b[39manxiety_scores[anxiety_data\u001b[38;5;241m.\u001b[39msocial_media_usage\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m                                      anxiety_data\u001b[38;5;241m.\u001b[39manxiety_scores[anxiety_data\u001b[38;5;241m.\u001b[39msocial_media_usage\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m Q7 \u001b[38;5;241m==\u001b[39m p_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(Q7) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for p-value but should be \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(p_value)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Got None for p-value but should be 0.03"
     ]
    }
   ],
   "source": [
    "# test_Q7\n",
    "import numpy as np\n",
    "p_value = np.round(stats.median_test(anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"Low\"], \n",
    "                                     anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"High\"])[1], 3)\n",
    "assert Q7 == p_value, \"Got \" + str(Q7) + \" for p-value but should be \" + str(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a57f4",
   "metadata": {},
   "source": [
    "### Q8: Are \"permutation shuffling test\" and \"median test\" methodologies parametric or nonparametric and why?\n",
    "\n",
    "A. Both are parametric since they both imply the assumption that the population medians are equal which subsequently implies that each population is normally distributed  \n",
    "\n",
    "B. Both are parametric since the boxplots of the data and histogram of the sampling distribution appear to be normally distributed  \n",
    "\n",
    "C. Both are nonparametric since if the two populations have different distributions then they couldn't both be normally distributed  \n",
    "\n",
    "D. Both are nonparametric since neither makes specific distributional assumptions (such as normality) about either of the populations  \n",
    "\n",
    "E. The former is parametric since it assumes the samples come from the same population while the latter is nonparametric since it only assumes the population medians are the same but not necessarily otherwise the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b198aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: your answer will be tested!\n",
    "Q8 = None # Assign either 'A' or 'B' or 'C' or 'D' to `Q8` instead of `None`\n",
    "# E.g., Q8 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e2178a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = 'The \"permutation shuffling test\" is based on simulation while the \"median test\" is not\\n'\n",
    "hint += \"since it is based on a theoretical derivation; but...\\n\"\n",
    "hint += \"is one of these nonparameteric while the other is parameteric?\\n\"\n",
    "hint += \"Review the hints in the previous question Q7...\\n\"\n",
    "test = Q8 == 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b158be3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Review the hints in the previous question Q7...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q8\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: Review the hints in the previous question Q7..."
     ]
    }
   ],
   "source": [
    "# test_Q8\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede7d590",
   "metadata": {},
   "source": [
    "### Q9: Use `scipy.stats.mannwhitneyu` to calculate a p-value which could be used to provide evidence of a difference between the two social media usage groups.\n",
    "\n",
    "#### Provide your answer rounded to 3 decimal places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406d4e1",
   "metadata": {},
   "source": [
    "> - Hint 1: the \"Mann-Whitney U test\" is based on a null hypothesis that assumes there is \"no actual distributional difference between two populations\" (here \"High\" and \"Low\" social media usage populations). \n",
    "> ```python\n",
    "> stats.mannwhitneyu(series_A, series_B)\n",
    "> # where `series_A` and `series_B` are your two samples\n",
    "> # Do not use `scipy.stats.wilcoxon`... that's for \"paired\" samples \n",
    "> # with one-to-one pairing of observations...\n",
    "> ```\n",
    "> - Hint 2: The \"Mann-Whitney U test\" is based on a null hypothesis that is identical to the assumption of the \"permutation shuffling test\" used to produce the initially simulated p-value (and is then of course again a stronger assumption than the \"median test\"); however, there is a slight difference in the observed test statistic used by the \"Mann-Whitney U test\" compared to the observed difference of medians used in the \"permutation shuffling test\"...\n",
    ">   - Using the assumption of \"no actual distributional difference between two populations\" implies that if all observations are \"ranked\" smallest to largest, the sum of the ranks should end up the same on average. This, however, means the \"Mann-Whitney U test\" will produce its p-value based on all the data (ranks totalling equivalently) as opposed to just considering the difference between the medians in two samples.  Making a p-value based on all the relative ranks of the samples will of course be more informative than just the medians of samples; so, even though the base assumption of the \"Mann-Whitney U test\" null hypothesis is the same as the permutation test, the data is used in a more powerful manner in the \"Mann-Whitney U test\"...\n",
    ">     - It's worth noting and keeping in mind that the different uses of data employed by different hypothesis tests can end up being more or less powerful based on how efficiently and holistically they make use of the information available in the data...\n",
    ">\n",
    ">\n",
    "> - Hint 3: The \"Mann-Whitney U test\" is a two sample test that is (of coures) distinct from the \"Wilcoxon Rank Sum test\" (`scipy.stats.wilcoxon`). The former is for two samples where the observations don't come in pairs; whereas, the latter is for when there are two samples but the observations have a natural pairing with each other.\n",
    ">    - Our samples don't involve having measurements on twins or something like that, so the our samples don't naturally come in pairs...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee764049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for your work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a301d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9: your answer will be tested!\n",
    "Q9 = None # Assign p-value rounded to 3 decimal places to Q9 instead of 'None'\n",
    "# E.g., Q9 = '0.987'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bca3e636",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Got None for p-value but should be 0.004",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q9\u001b[39;00m\n\u001b[0;32m      2\u001b[0m p_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(stats\u001b[39m.\u001b[39mmannwhitneyu(anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLow\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m      3\u001b[0m                                       anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHigh\u001b[39m\u001b[39m\"\u001b[39m])[\u001b[39m1\u001b[39m], \u001b[39m3\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[39massert\u001b[39;00m Q9 \u001b[39m==\u001b[39m p_value, \u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(Q9) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m for p-value but should be \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(p_value)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Got None for p-value but should be 0.004"
     ]
    }
   ],
   "source": [
    "# test_Q9\n",
    "p_value = np.round(stats.mannwhitneyu(anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"Low\"], \n",
    "                                      anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"High\"])[1], 3)\n",
    "assert Q9 == p_value, \"Got \" + str(Q9) + \" for p-value but should be \" + str(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8cbd1a",
   "metadata": {},
   "source": [
    "### Q10: Use `scipy.stats.ttest_ind` to calculate a p-value which could be used to provide evidence of a difference between the two social media usage groups.\n",
    "\n",
    "#### Provide your answer rounded to 3 decimal places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f6fee",
   "metadata": {},
   "source": [
    "> - Hint 1: The \"two-sample t-test\" has a null hypothesis that assumes the means of two populations (here mean anxiety levels of \"High\" and \"Low\" social media usage populations) are equal and that the samples are drawn from normally distributed populations.\n",
    "> ```python\n",
    "> stats.ttest_ind(series_A, series_B, equal_var=False)\n",
    "> # where `series_A` and `series_B` are your two samples\n",
    "> # Do not use `stats.ttest_rel`... that's for \"paired\" samples \n",
    "> # with one-to-one pairing of observations...\n",
    "> ```\n",
    "> - Hint 2: A mean is of course distinct from a median, generally speaking; however, the mean and median are the same for a population that is symmetric such as a normally distributed population; thus, the assumption of the null hypothesis that the distributions are normally disributed and have the same means here implies that they have the same medians...\n",
    ">\n",
    ">\n",
    "> - Hint 3: When doing a two sample t-test it is possible to make additional assumptions about the two normal populations under examination, such as if the variances (or equivalently the standard deviations) of the two populations are the same or not. By default `stats.ttest_ind` uses `equal_var=True`; but, given the observed boxplots of the two samples in question, it seems like `equal_var=False` is a better assumption for this test; so, that's what you should use here as in the example code above...\n",
    ">\n",
    ">\n",
    "> - Hint 4: There is another function `stats.ttest_rel` which is (of course) distinct from `stats.ttest_ind`. The difference between these is analagous to the difference between the \"Wilcoxon Rank Sum test\" (`scipy.stats.wilcoxon`) and the \"Mann-Whitney U test\" (`scipy.stats.mannwhitneyu`); namely, the former is for when the observations have a natural pairing with each other, while the latter is when the observations don't come in pairs.\n",
    ">    - Our samples don't involve having measurements on twins or something like that, so the our samples don't naturally come in pairs...\n",
    ">\n",
    ">\n",
    "> - Hint 5: The p-value from a t-test is theoretically derived on the basis of the normality assumptions it makes about the population(s) in question; but, the p-value from the \"median test\" and \"Mann-Whitney U test\" are also theoretically derived; so, the use of a theoretical derivation is not what distinguishes between these tests; however, there is definitely a distinction between theoretically derived tests and the \"permutation shuffling test\" since that p-value is based on simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fcec329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for your work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "140593d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10: your answer will be tested!\n",
    "Q10 = None # Assign p-value rounded to 3 decimal places to Q10 instead of 'None'\n",
    "# E.g., Q10 = '0.987'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddf35d83",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Got None for p-value but should be 0.001",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q11\u001b[39;00m\n\u001b[0;32m      2\u001b[0m p_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(stats\u001b[39m.\u001b[39mttest_ind(anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLow\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m      3\u001b[0m                                    anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHigh\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m      4\u001b[0m                                    equal_var\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m1\u001b[39m], \u001b[39m3\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[39massert\u001b[39;00m Q11 \u001b[39m==\u001b[39m p_value, \u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(Q11) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m for p-value but should be \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(p_value)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Got None for p-value but should be 0.001"
     ]
    }
   ],
   "source": [
    "# test_Q10\n",
    "p_value = np.round(stats.ttest_ind(anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"Low\"], \n",
    "                                   anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"High\"], \n",
    "                                   equal_var=False)[1], 3)\n",
    "assert Q10 == p_value, \"Got \" + str(Q10) + \" for p-value but should be \" + str(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d699173e",
   "metadata": {},
   "source": [
    "### Q11: Are \"Mann-Whitney U test\" and \"two-sample t-test\" methodologies parametric or nonparametric and why?\n",
    "\n",
    "A. Both are parametric since both imply the assumption that the population medians are equal which subsequently implies that we are assuming the samples are drawn from normally distributed populations  \n",
    "\n",
    "B. Both are parametric since the boxplots of the data and histogram of the sampling distribution appear to be normally distributed and the assumption of \"no actual difference between groups\" can only occur if each population is normally distributed   \n",
    "\n",
    "C. Both are nonparametric since neither makes specific distributional assumptions (such as normality) regarding the populations the two samples come from since a sample can never be normally distributed  \n",
    "\n",
    "D. The former is nonparametric since the assumption that the means for each group being equal does not imply that the populations are normally distributed while the latter is parametric since if the two populations have different distributions then only one can be normally distributed   \n",
    "\n",
    "E. The former is nonparametric since it only assumes the samples come from the same population while the latter is parametric since it instead makes specific distributional assumptions (such as normality) regarding the populations the two samples come from\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dad64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11: your answer will be tested!\n",
    "Q11 = None # Assign either 'A' or 'B' or 'C' or 'D' to `Q11` instead of `None`\n",
    "# E.g., Q11 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d677814",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Q11' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m hint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe hints and conversation in Q7 and Q9 relative to those in Q10 should be helpful here...\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mQ11\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Q11' is not defined"
     ]
    }
   ],
   "source": [
    "hint = 'The key consideration being whether or not any specific distribution assumptions'\n",
    "hint += 'such as normality are made about the populations under consideration.\\n\\n'\n",
    "hint = 'The hints and conversation in Q7 and Q9 relative to those in Q10 should be helpful\\n'\n",
    "hint += 'when considering the nature of nonparameteric versus nonparametric tests...'\n",
    "\n",
    "test = Q11 == 'E'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "149223f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The hints and conversation in Q7 and Q9 relative to those in Q11 should be helpful here...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q12\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: The hints and conversation in Q7 and Q9 relative to those in Q11 should be helpful here..."
     ]
    }
   ],
   "source": [
    "# test_Q11\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ac2ac",
   "metadata": {},
   "source": [
    "### Q12: Give the strength of evidence against the null hypothesis for the three tests considered above.\n",
    "\n",
    "1. \"Median test\" which specifies a null hypothesis that assumes the medians of the two populations are equal\n",
    "2. \"Mann-Whitney U test\" which specifies a null hypothesis that assumes the two populations are identical\n",
    "3. \"Two-sample t-test\" which specifies a null hypothesis that assumes the two populations are normally distributed with the same means<br>(but different standard deviations, for the specification above)\n",
    "\n",
    "A. `0.10 < p-value`: No evidence against the null hypothesis  \n",
    "\n",
    "B. `0.05 < p-value <= 0.10`: Weak evidence against the null hypothesis  \n",
    "\n",
    "C. `0.01 < p-value <= 0.05`: Moderate evidence against the null hypothesis  \n",
    "\n",
    "D. `0.001 <= p-value <= 0.01`: Strong evidence against the null hypothesis  \n",
    "\n",
    "E. `p-value < 0.001`: Very strong evidence against the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "161f5275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q12: your answer will be tested!\n",
    "median_test_evidence = None # Assign either 'A' or 'B' or 'C', 'D', 'E' based on the options above\n",
    "mann_whitney_U_test_evidence = None # Assign either 'A' or 'B' or 'C', 'D', 'E' based on the options above\n",
    "two_sample_t_test = None # Assign either 'A' or 'B' or 'C', 'D', 'E' based on the options above\n",
    "Q12 = (median_test_evidence, mann_whitney_U_test_evidence, two_sample_t_test) \n",
    "# Assign a triple tuple comprised of 'A's, 'B's, 'C's, 'D's and/or 'E' to `Q12` \n",
    "# in the order of Median test, Mann-Whitney U test, and Two-sample t-test\n",
    "# instead of the `None` triple tuple `(None,None,None)` \n",
    "# E.g., Q12 = ('A','B','C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72fa649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = 'The p-values for the three tests were 0.03, 0.004, and 0.001, respectively...'\n",
    "test = Q12 == ('C', 'D', 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a9e48c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The p-values for the three tests were 0.03, 0.004, and 0.001, respectively...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q13\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: The p-values for the three tests were 0.03, 0.004, and 0.001, respectively..."
     ]
    }
   ],
   "source": [
    "# test_Q12\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86716ca6",
   "metadata": {},
   "source": [
    "### Q13: Relative to the p-value calculations based on `scipy.stats.ttest_1samp` and `scipy.stats.binom` from the homework exercise and tutorial assignment of the previous week, which of the following is correct?\n",
    "\n",
    "A. The `stats.ttest_1samp` and `stats.binom` methods **theoretically** derive p-value under their null hypothesis, while `stats.median_test`, `stats.mannwhitneyu`, and `stats.ttest_ind` do not  \n",
    "\n",
    "B. The `stats.ttest_1samp` and `stats.ttest_ind` methods use continuous approximations of the theoretical binomial sampling distribution of the `stats.binom` and `stats.median_test` and `stats.mannwhitneyu` methods, respectively, which is why these t-tests produce nonparametric p-values  \n",
    "\n",
    "C. The `stats.ttest_1samp`, `stats.ttest_ind`, and `stats.ttest_rel` methods are parametric due to their assumption regarding the normally distributed nature of the populations they consider; whereas, the `stats.binom`, `stats.median_test`, `stats.mannwhitneyu`, and `stats.wilcoxon` methods are nonparametric since they rely on no specific population assumptions such as distributional normality. \n",
    "\n",
    "D. With respect to the null hypothesis specification, \n",
    "`stats.ttest_1samp` is most similar to `stats.ttest_ind` and `stats.ttest_rel`, \n",
    "while `stats.binom` is most closely related to `stats.median_test`, `stats.mannwhitneyu`, and `stats.wilcoxon`.\n",
    "\n",
    "E. `stats.ttest_1samp` and `stats.binom` are only good for 50/50 chance problems; so, `stats.median_test`, `stats.mannwhitneyu`, and `stats.ttest_ind` exist in order to consider different comparision populations.  \n",
    " \n",
    "> - Hint 1: The following \"fun fact\" is not at all obvious at this stage; but, it would be possible to reformulate the p-value computed from the `stats.median_test` using `stats.binom`, and it would be similarly possible to reformulate the p-value computed from `stats.ttest_rel` using `stats.ttest_1samp`; however, the null hypotheses for `stats.median_test` and `stats.ttest_rel` always involve two populations; whereas, the null hypotheses for `stats.binom` and `stats.ttest_1samp` can support hypotheses involving only a single population...  `stats.ttest_1samp`, `stats.ttest_ind`, and `stats.ttest_rel` are analagous with respect to the distributional assumptions they make on the populations they consider, but not necessarily with respect to their specific problem contexts, which address different kinds of comparison and hence involve qualitatively different forms of null hypotheses...\n",
    "> - Hint 2: \n",
    "> ```python\n",
    "> print((1-stats.binom(n=100, p=0.5).cdf(60-1))*2)\n",
    "> # Probability of getting a combination more as or extreme than 60 heads in 100 coin flips for a 50-50 coin\n",
    "> coin_flips = [1] * 60 + [0] * 40  # 1 for head, 0 for tails\n",
    "> stats.ttest_1samp(coin_flips, 0.5) \n",
    "> # Probability of getting a combination as or more extreme than 60 heads in 100 coin flips for a 50-50 coin\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2c22e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05688793364098088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=2.0310096011589898, pvalue=0.04493472521263044, df=99)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell for some scratch work if desired...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250b3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13: your answer will be tested!\n",
    "Q13 = None # Assign either 'A', 'B', 'C', 'D', or 'E' to `Q13` instead of `None`\n",
    "# E.g., Q13 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6a25dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"A is wrong because all of these methods are based on theoretical derivations...\\n\"\n",
    "hint += \"A careful reading of B should suggest why it is wrong...\\n\"\n",
    "hint += \"D has things mixed up... `stats.ttest_1samp` and `stats.binom` have similar null hypotheses, etc.\\n\"\n",
    "hint += \"as described and characterized in the hint...\\n\"\n",
    "hint += \"Do you see why E makes an overly strict claim on the null hypotheses these methods consider?\"\n",
    "\n",
    "test = Q13 == 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f0a666",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "A is wrong because all of these methods are based on theoretical derivations...\nA careful reading of B should suggest why it is wrong...\nD has things mixed up... `stats.ttest_1samp` and `stats.binom` have similar null hypotheses, etc.\nas described in the hint...\nDo you see why E makes an overly strict claim on the null hypotheses these methods consider?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test_Q14\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test, hint\n",
      "\u001b[0;31mAssertionError\u001b[0m: A is wrong because all of these methods are based on theoretical derivations...\nA careful reading of B should suggest why it is wrong...\nD has things mixed up... `stats.ttest_1samp` and `stats.binom` have similar null hypotheses, etc.\nas described in the hint...\nDo you see why E makes an overly strict claim on the null hypotheses these methods consider?"
     ]
    }
   ],
   "source": [
    "# test_Q13\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7a873",
   "metadata": {},
   "source": [
    "### Q14: Create a 90% bootstrap confidence interval estimating the difference in median anxiety scores between the social media usage groups. \n",
    "\n",
    "#### Provide your interval endpoint answers rounded to 3 decimal places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72513439",
   "metadata": {},
   "source": [
    "> - Hint 1: The process within the `for` loop in `Q4` is not quite right since it's based on the assumption of a null hypothesis that the labels don't matter; however, when making a confidence interval we do think the labels matter! So, the `for` loop for a confidence interval should instead provide a simulation producing repeated pairs of bootstrap samples which can then be used to create simulated median difference test statistics that are samples from the bootrapped sampling distribution of the difference in medians...  \n",
    ">\n",
    ">\n",
    "> - Hint 2: Don't forget about the `np.quantile()` function...\n",
    ">\n",
    ">\n",
    "> - Hint 3: Be careful that you haven't accidentally overwritten the values in `anxiety_data.anxiety_scores`...\n",
    ">   - Working instead with something like `bootstrapped_data = anxiety_data.copy()` and `bootstrapped_anxiety_scores = anxiety_data.anxiety_scores.values.copy()` would help protect against this... and you can tell pretty quickly that you might be making this mistake if your simulated median difference statistics all end up having the same value!\n",
    ">\n",
    ">\n",
    "> - Hint 4: code like the following\n",
    ">   ```python\n",
    ">   bootstrapped_data['anxiety_scores'][anxiety_data.social_media_usage==\"Low\"] = \\\n",
    ">      anxiety_data['anxiety_scores'][anxiety_data.social_media_usage==\"Low\"].\\\n",
    ">        sample(frac=1, replace=True).values\n",
    ">   ```\n",
    ">   will produce a\n",
    ">\n",
    ">   `SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame`  \n",
    ">\n",
    ">   because `bootstrapped_data['anxiety_scores'][anxiety_data.social_media_usage==\"Low\"]` is itself a \"slice\" of a `pd.DataFrame` even if `bootstrapped_data = anxiety_data.copy()`; so, instead, sequentially assign into something like \n",
    ">   - `bootstrapped_anxiety_scores = anxiety_data.anxiety_scores.values.copy()` \n",
    ">     - `bootstrapped_anxiety_scores[anxiety_data.social_media_usage==\"Low\"] = ...`\n",
    ">     - `bootstrapped_anxiety_scores[anxiety_data.social_media_usage==\"High\"] = ...`\n",
    ">   - and finally `bootstrapped_data['anxiety_scores'] = bootstrapped_anxiety_scores` without any \"slice\" usage in order to use \n",
    ">   - `np.diff(bootstrapped_data.groupby('social_media_usage').median().values.flatten())[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4057fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for scratch work if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "198c5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the following line at the top! And, replace `None` below with the three digit integer \n",
    "np.random.seed(None) # made from the 1st, 3rd, and 5th digits or your student number. \n",
    "\n",
    "# Code your bootstrap sampling distribution simulation here... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f10fa7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_digit_random_nubmer_seed = None \n",
    "# Match the integer created from the 1st, 3rd, and 5th digits of your student number used above...\n",
    "# your results must be based on this random number seed so that they can be confirmed during autotesting\n",
    "number_of_bootstrap_sample_repititions = None # number of simulated median difference test statistics\n",
    "# sampled from the bootstrapped sampling distribution of the difference in medians\n",
    "the_90percent_confidence_interval = (None, None) # Assign your 90% confidence interval lower and upper bounds\n",
    "# Round to 3 digits of accuracy\n",
    "Q14 = (three_digit_random_nubmer_seed, number_of_bootstrap_sample_repititions, the_90percent_confidence_interval)\n",
    "# E.g. `Q14 = (123, 10000, (0.123, 0.456))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b4c39a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m# changes to the new data frame will also appear in the original version of the data frame as well(!)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m bootstrapped_anxiety_scores \u001b[39m=\u001b[39m anxiety_data\u001b[39m.\u001b[39manxiety_scores\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(num_samples):\n\u001b[0;32m     14\u001b[0m     bootstrapped_anxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLow\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[0;32m     15\u001b[0m     anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLow\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     17\u001b[0m     bootstrapped_anxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHigh\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[0;32m     18\u001b[0m     anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHigh\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mvalues\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# test_Q14\n",
    "#Q14 = (123, 10000, (0.123, 0.456)) \n",
    "seed, num_samples, interval = Q14\n",
    "\n",
    "np.random.seed(seed) # make the simulation reproducible...\n",
    "simulated_values = []\n",
    "\n",
    "simdata = anxiety_data.copy() # you should essentially always use `.copy()` for data frames; otherwise,\n",
    "# changes to the new data frame will also appear in the original version of the data frame as well(!)\n",
    "bootstrapped_anxiety_scores = anxiety_data.anxiety_scores.values.copy()\n",
    "\n",
    "for i in range(num_samples):\n",
    "    \n",
    "    # \"Low\" is bootstrapped first then \"High\": psuedorandomness results will be different\n",
    "    # if the order is different or if this is done in some other manner...\n",
    "    # this could be what's happening if your confidence is pretty close but numerically different\n",
    "\n",
    "    bootstrapped_anxiety_scores[anxiety_data.social_media_usage==\"Low\"] = \\\n",
    "    anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"Low\"].sample(frac=1, replace=True).values\n",
    "    \n",
    "    bootstrapped_anxiety_scores[anxiety_data.social_media_usage==\"High\"] = \\\n",
    "    anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"High\"].sample(frac=1, replace=True).values\n",
    "    \n",
    "    simdata['anxiety_scores'] = bootstrapped_anxiety_scores\n",
    "    \n",
    "    simvalue = np.diff(simdata.groupby('social_media_usage').median().values.flatten())[0]\n",
    "    simulated_values += [simvalue]\n",
    "\n",
    "calc_interval = tuple(np.round(np.quantile(simulated_values,(0.05, .95)), 3))\n",
    "\n",
    "assert calc_interval == interval, \"You got \" + str(interval) + \" for your 90% confidence interval but should be \" + str(calc_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a870f5",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Airbags\n",
    "The table below is adapted from a \"Biostatistics for the Biological and Health Sciences\" textbook example and presents data from a random sample of passengers sitting in the front seat of cars involved in car crashes. Based on this data we'd like to make a determination as to whether or not death rates differ for passengers in cars with airbags and passengers in cars without airbags.\n",
    "\n",
    "|                           | Airbag available | No airbag available |\n",
    "|---------------------------|------------------|---------------------|                           \n",
    "| Passenger Fatalities      |  45              | 62                  |\n",
    "| Total number of Passengers|  10,541          | 9,867               |\n",
    "\n",
    "- The code below creates a pandas data frame for this problem with the help of the `numpy.repeat` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7c2b718",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m crash_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrepeat([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mairbag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_airbag\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;241m10541\u001b[39m, \u001b[38;5;241m9867\u001b[39m]), \n\u001b[1;32m      2\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcome\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrepeat([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdead\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malive\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdead\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malive\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m10541\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m62\u001b[39m, \u001b[38;5;241m9867\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m62\u001b[39m])})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "crash_data = pd.DataFrame({'group': np.repeat([\"airbag\", \"no_airbag\"], [10541, 9867]), \n",
    "                           'outcome': np.repeat([\"dead\", \"alive\", \"dead\", \"alive\"], [45, 10541-45, 62, 9867-62])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50ade0",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q15: In simple terms, state the claim of the *null hypothesis* for the context above that we are naturally trying to provide evidence against.  Then state this formally in terms of the two population parameters -- probabilities of death $p_{airbag}$ and $p_{no-airbag}$ -- in question. Finally, formally state the *alternative hypothesis* $H_1$ that makes this a *one-sided hypothesis test* such that (during the p-value calculation process) \"as or more extreme\" only considers evidence indicating that survival rates are strictly better in cars with airbags. \n",
    "\n",
    "#### Provide your written answer in the markdown cell below.\n",
    "\n",
    "> - Hint 1: Formulate the null and alternative hypotheses in the requested 'one-sided' manner (as opposed to as a 'two-sided' specification) by using using a \"less than\" \"$<$\" sign as opposed to the typical \"$H_1: H_0\\text{ is false}$\".  Doing so indicates that there is no evidence against the null hypothesis if the survival rates are worse for cars with airbags; but, on the other hand, this actually tends to reduce p-values by a factor of two since it means only considering \"as or more extreme\" to be on one side (\"better than\" direction only) of the sampling distribution implied by the null hypothesis.\n",
    ">   - You might have come across the idea that airbags can actually be dangerous in some situations; but, for now let's just consider airbags as being safety devices that might offer improvements in that regard... as we shall shortly see, this is generally suggested by the data at hand, anyway. \n",
    ">\n",
    ">\n",
    "> - Hint 2: In the previous \"Social Media and Anxiety\" example it was suggested that it might be plausible for there to be a pre-existing association between anxiety and the choice to use social media more frequently. In this case, does it feel similarly possible that people who are more likely to die in a car crash (for whatever reason) would also be people who would choose to drive a car without an airbag? It feels like an argument of some kind of \"confounding\" affecting things here might be less likely than anxious people using more social media; but, what kind of story could you tell which might in fact produce \"confounding\" in the current car crash surival context? \n",
    "\n",
    "- The TA will manually review and confirm the correctness of your submitted answer for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3418eb",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\n\"\n",
    "hint += \"Included as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += '''\n",
    "The natural null hypothesis that we'd look to provide evidence against in this context  \n",
    "is that the chance of death in a car crash for cars with and without airbags,  \n",
    "$p_{airbag}$ and $p_{no-airbag}$, respectively, is the same. \n",
    "\n",
    "The formal null and alternative hypothesis specifications for a one-sided hypothesis test\n",
    "here would thus be\n",
    "\n",
    "$$H_0: p_{airbag} = p_{no-airbag} \\\\quad H_A:p_{airbag} < p_{no-airbag}$$\n",
    "\n",
    "which means we can provide evidence against the null hypothesis if our observed difference\n",
    "test statistic $\\\\hat p_{no-airbag} - \\\\hat p_{airbag}$ is positive; and, when computing\n",
    "p-values \"as or more extreme\" will only consider test statistics sampled under the assumption\n",
    "of the null hypothesis which are at least as large as the observed test statistic. \n",
    "\n",
    "Generally, one-sided hypothesis tests lead to smaller p-values since only half of the \n",
    "outcomes that would usually be considered \"as or more extreme\" are now counted as being so.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d15fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q15\n",
    "assert False, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a37b9c",
   "metadata": {},
   "source": [
    "### Q16: The code below shows that we observe only $0.2\\%$ less deaths in crashes for cars that have airbags compared to those that don't; but, that the proporitional increase of deaths in crashes for cars that have no airbags is $1.47 \\approx \\frac{0.006284}{0.004269}$.  \n",
    "\n",
    "#### Write 2-3 sentences in the markdown cell below exploring your sensibilities regarding this difference in absolute versus relative risk. \n",
    "\n",
    "```python\n",
    "crash_data['outcome_numeric'] = (crash_data['outcome']=='dead') # Boolean True/False \n",
    "crash_data.groupby('group')['outcome_numeric'].mean() # will coerce to 0/1 numeric\n",
    "# group\n",
    "# airbag       0.004269\n",
    "# no_airbag    0.006284\n",
    "np.diff(crash_data.groupby('group')['outcome_numeric'].mean().values.flatten())[0]\n",
    "# 0.002014526818295126\n",
    "np.divide(*np.flip(crash_data.groupby('group')['outcome_numeric'].mean().values.flatten()))\n",
    "# 1.471891715369976\n",
    "```\n",
    "\n",
    "- You can compare your answer with the example solution provided by MarkUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f205846",
   "metadata": {},
   "source": [
    "> Answer here...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7159b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\n\"\n",
    "hint += \"Included as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += '''\n",
    "The absolute risk of death in a car crash is fairly low, at 0.5%; however,\n",
    "the relative difference observed indicates a nearly 50% increase in deaths\n",
    "for car crashes where the cars don't have airbags...\n",
    "\n",
    "Depending on ones sensibilities, a 0.2% absolute increased risk of death in\n",
    "a car crash for cars that don't have airbags might not seem particularly \n",
    "concerning; but, on the other hand, in a relative sense, this increased risk\n",
    "is fairly substantial.\n",
    "\n",
    "Because dying in a car crash is a very rare event, it seems reasonable to \n",
    "find the increased safetey unimpressive; but, for those who wish to improve\n",
    "their safety whenever possible, the empirical evidence suggests airbags\n",
    "might be a way to do this, particularly when considering the situation from\n",
    "a relative perspective, where the empirically observed 50% increased risk\n",
    "of death could appear quite concerning (in the relative sense)... \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae4b538",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\n\nThe absolute risk of death in a car crash is fairly low, at 0.5%; however,\nthe relative difference observed indicates a nearly 50% increase in deaths\nfor car crashes where the cars don't have airbags...\n\nDepending on ones sensibilities, a 0.2% absolute increased risk of death in\na car crash for cars that don't have airbags might not seem particularly \nconcerning; but, on the other hand, in a relative sense, this increased risk\nis fairly substantial.\n\nBecause dying in a car crash is a very rare event, it seems reasonable to \nfind the increased safetey unimpressive; but, for those who wish to improve\ntheir safety whenever possible, the empirical evidence suggests airbags\nmight be a way to do this.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test_Q16\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, hint\n",
      "\u001b[0;31mAssertionError\u001b[0m: \n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\n\nThe absolute risk of death in a car crash is fairly low, at 0.5%; however,\nthe relative difference observed indicates a nearly 50% increase in deaths\nfor car crashes where the cars don't have airbags...\n\nDepending on ones sensibilities, a 0.2% absolute increased risk of death in\na car crash for cars that don't have airbags might not seem particularly \nconcerning; but, on the other hand, in a relative sense, this increased risk\nis fairly substantial.\n\nBecause dying in a car crash is a very rare event, it seems reasonable to \nfind the increased safetey unimpressive; but, for those who wish to improve\ntheir safety whenever possible, the empirical evidence suggests airbags\nmight be a way to do this.\n"
     ]
    }
   ],
   "source": [
    "# test_Q16\n",
    "assert False, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0741b",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q17: Use label \"permutation shuffling\" to simulate and visualize the sampling distribution of the test statistic of the difference between $\\hat p_{no-airbag}$ and $\\hat p_{airbag}$ under the assumption that the *null hypothesis* stated in the previous question is true; then, provide a (one sided) \"permutation permutation test\" p-value of the observed test statistic relative to this simulated sampling distribution and indicate the strength of evidence provided against the null hypothesis above based on this simulated p-value.\n",
    "\n",
    "A. `0.10 < p-value`: No evidence against the null hypothesis  \n",
    "\n",
    "B. `0.05 < p-value <= 0.10`: Weak evidence against the null hypothesis  \n",
    "\n",
    "C. `0.01 < p-value <= 0.05`: Moderate evidence against the null hypothesis  \n",
    "\n",
    "D. `0.001 < p-value <= 0.01`: Strong evidence against the null hypothesis  \n",
    "\n",
    "E. `p-value <= 0.001`: Very strong evidence against the null hypothesis\n",
    "\n",
    "#### Provide your p-value with 3 digits of accuracy using `np.round(...,3)`.\n",
    "\n",
    "> - Hint 1: This should be a one-sided p-value for the one-sided null hypothesis specified above: how is \"as or more extreme\" calculated in this case?\n",
    ">   - Have we helped strengthen our evidence against the null hypothesis by using a one-sided hypothesis test as opposed to a two-sided hypothesis test?  If you try it out you'll likely see that indeed we have... \n",
    ">\n",
    ">\n",
    "> - Hint 2: The assumption that the *null hypothesis* stated in the previous question is true implies that the two samples must come from identical populations (which have identical survivial proportions); thus, a permutation test p-value similar to the one computed in Q4 is an appropriate nonparametric p-value for this context. \n",
    ">   - Of course we could also choose to use the alternative methods form computing p-values that we've encountered above (although we'd have to take care to use them so that they're based on a one-sided null hypothesis as opposed to a two sided null hypothesis...); but, for this question please create a \"permutation shuffling test\" p-value in order to practice this kind of simulation test. \n",
    ">\n",
    ">\n",
    "> - Hint 3: This problem considers *statistical significance* as opposed to *practical significance*: the question of *practical significance* was addressed in the previous problem where the 0.2% absolute risk increse and the 1.47 relative proprtional risk increase were considered. Always remember that even we're able to use this data to provide statistical evidence against the (one-sided) null hypothesis based that there is no safety difference, there's always still the real question of *practical significance*: is the difference that we estimate sufficiently large enough to be practically meaningful? \n",
    ">\n",
    ">\n",
    "> - Hint 4: Rather than coercing boolean values to compute proportions as is done in the previous problem, you could consider using something like `data.replace({'dead': 1, 'alive': 0})` to replace 'dead' and 'alive' outcomes with 1's and 0's as an initial first step that might simplify working with proportions slightly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f21b34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for scratch work if needed\n",
    "# - Don't use variables here that haven't been defined in previuos cells up above since that would\n",
    "#   cause a \"variable not defined error\" when the notebook is run sequentially by MarkUs autotesting\n",
    "# - Instead use newly created variables by using them in new cells that you add below where they're defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74111033",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Keep the following line at the top! And, replace `None` below with the three digit integer \n",
    "np.random.seed(None) # made from the 1st, 3rd, and 5th digits or your student number. \n",
    "\n",
    "# Code your \"permutation shuffling test\" simulation here... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9dff4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_digit_random_nubmer_seed = None\n",
    "# Match the integer created from the 1st, 3rd, and 5th digits of your student number used above...\n",
    "# your results must be based on this random number seed so that they can be confirmed during autotesting\n",
    "number_of_bootstrap_sample_repititions = None # integer number of simulated difference test statistics\n",
    "# drawn from the sampling distribution of the null hypothesis used to calculate your p-value\n",
    "permutation_p_value = None # Assign to p_value your calculated p-value rounded to 3 decimal places\n",
    "strength_of_evidence_against_H0 = None # Assign either 'A' or 'B' or 'C' or 'D' or 'E' instead of `None`\n",
    "# E.g., strength_of_evidence_against_H0 = 'A'\n",
    "\n",
    "Q17 = (three_digit_random_nubmer_seed, number_of_bootstrap_sample_repititions, \n",
    "       permutation_p_value, strength_of_evidence_against_H0)\n",
    "# E.g. `Q17 = (123, 10000, 0.123, 'A')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "156e022e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# Stores test statistics simulated from the sampling distribution under H0\u001b[39;00m\n\u001b[0;32m     13\u001b[0m simulated_test_statistics_under_H0 \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(num_reps):   \n\u001b[0;32m     16\u001b[0m     \u001b[39m# shuffle group labels under null hypothesis assumption\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     simdata[\u001b[39m'\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_ones_and_zeros[\u001b[39m'\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mvalues  \n\u001b[0;32m     18\u001b[0m     \u001b[39m# simulated test statistic\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# test_Q17\n",
    "#Q17 = (123, 10000, 0.123, 'A')\n",
    "seed, num_reps, p_value, evidence = Q17\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Replace \"dead\" outcome with 1 and \"alive\" with 0 so `.mean()` gives proportion died\n",
    "# The `crash_data` Data Frame is not changed: the altered version is stored in `data_ones_and_zeros`\n",
    "data_ones_and_zeros = crash_data.replace({'dead': 1, 'alive': 0})   \n",
    "observed_test_statistic = np.diff(data_ones_and_zeros.groupby('group')['outcome'].mean())  \n",
    "simdata = data_ones_and_zeros.copy() # for shuffling to create permuation test\n",
    "\n",
    "# Stores test statistics simulated from the sampling distribution under H0\n",
    "simulated_test_statistics_under_H0 = np.array([0.0]*num_reps)\n",
    "\n",
    "for i in range(num_reps):   \n",
    "    # shuffle group labels under null hypothesis assumption\n",
    "    simdata['group'] = data_ones_and_zeros['group'].sample(frac=1).values  \n",
    "    # simulated test statistic\n",
    "    simulated_test_statistic_under_H0 = np.diff(simdata.groupby('group')['outcome'].mean())\n",
    "    simulated_test_statistics_under_H0[i] = simulated_test_statistic_under_H0\n",
    "\n",
    "# Calculate p-value: no abs function as this is a one-sided test!\n",
    "num_more_extreme = (simulated_test_statistics_under_H0 >= observed_test_statistic).sum() \n",
    "calc_p_value = np.round(num_more_extreme / num_reps, 3)\n",
    "\n",
    "if calc_p_value > 0.10:\n",
    "    evidence_test = evidence == 'A'\n",
    "    actually_correct_evidence_choice = 'A'\n",
    "elif 0.05 < calc_p_value <= 0.10:\n",
    "    evidence_test = evidence == 'B'\n",
    "    actually_correct_evidence_choice = 'B'\n",
    "elif 0.01 < calc_p_value <= 0.05:\n",
    "    evidence_test = evidence == 'C'\n",
    "    actually_correct_evidence_choice = 'C'\n",
    "elif 0.001 < calc_p_value <= 0.01:\n",
    "    evidence_test = evidence == 'D'\n",
    "    actually_correct_evidence_choice = 'D'\n",
    "else:\n",
    "    evidence_test = evidence == 'E'\n",
    "    actually_correct_evidence_choice = 'E'\n",
    "\n",
    "evidence_choice_in_words = {'A': 'NO', 'B': 'WEAK', 'C': 'MODERATE', 'D': 'STRONG', 'E': 'VERY STRONG'}\n",
    "\n",
    "hint = \"You got \" + str(p_value) + \" for calculated p-value and it should be \" + str(calc_p_value) + \".\\n\"\n",
    "hint += \"You stated your p_value represents \" + evidence_choice_in_words[evidence] + \" evidence against the \\n\"\n",
    "hint += \"null hypothesis and it should represent \" + evidence_choice_in_words[actually_correct_evidence_choice]\n",
    "hint += \" evidence against the null hypothesis.\\n\\n\"\n",
    "\n",
    "hint += \"The null hypothesis assumes that there's no difference in the probability \\n\"\n",
    "hint += \"of death between the 'airbag' and 'no-airbag' populations in question.\\n\"\n",
    "hint += \"A p-value of \" + str(calc_p_value) + \" represents \" + evidence_choice_in_words[actually_correct_evidence_choice] \n",
    "hint += \" evidence against the null hypothesis.\\n\"\n",
    "hint += \"that the probability of death between the 'airbag' and 'no-airbag' groups is the same.\\n\\n\"\n",
    "hint += \"If the evidence is quite good, a one-sided hypothesis test would likely choose to reject\\n\"\n",
    "hint += \"the null hypothesis in favor of the alternative hypothesis and we might thus choose to\\n\"\n",
    "hint += \"believe that cars without airbags are MORE likely to result in death than cars with airbags.\"\n",
    "\n",
    "assert (calc_p_value == np.round(p_value,3)) and evidence_test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6da9829",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q18: Create a 95% bootstrap confidence interval estimating the relative (ratio) risk in probability of death ($p_{no-airbag}$ divided by $p_{airbag}$) between passengers in cars with airbags and passengers in cars without airbags. Then visualize the distribution of the bootstrapped sample proportion ratios.\n",
    "\n",
    "#### Provide your bootstrap confidence interval endpoint answers rounded to 2 decimal places.\n",
    "\n",
    "> - Hint 1: You could first make this analysis for the difference between these two proportions, which would be more analagous to the \"permutation shuffling test\" used in the previous question, and then change the bootstrapped test statistic from a difference to the desired ratio...\n",
    ">   - The difference between the difference and ratio test statistic being used is a question of absolute risk versus relative risk, as was discussed in Q16... making a confidence interval for the relative risk means we've lost the context of the absolute risk, but of course this allows us to emphasize the relative risk in our bootstrapped confidence interval range estimation.\n",
    ">\n",
    ">\n",
    "> - Hint 2: If the test statistic under consideration was the difference rather than the ratio, we'd need to round our answers to 5 decimal places, since the actual absolute probabilities under consideration are quite small (at less than 1%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56c836d7",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# space for scratch work if needed\n",
    "# - Don't use variables here that haven't been defined in previuos cells up above since that would\n",
    "#   cause a \"variable not defined error\" when the notebook is run sequentially by MarkUs autotesting\n",
    "# - Instead use newly created variables by using them in new cells that you add below where they're defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a4c5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the following line at the top! And, replace `None` below with the three digit integer \n",
    "np.random.seed(None) # made from the 1st, 3rd, and 5th digits or your student number. \n",
    "\n",
    "# Code your bootstrap sampling distribution simulation here... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "912f9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of the bootstrapped sample proportion differences here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3222d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_digit_random_nubmer_seed = None\n",
    "# Match the integer created from the 1st, 3rd, and 5th digits of your student number used above...\n",
    "# your results must be based on this random number seed so that they can be confirmed during autotesting\n",
    "number_of_bootstrap_sample_repititions = None # number of simulated proportion difference test statistics\n",
    "# sampled from the bootstrapped sampling distribution of the difference in death proportions\n",
    "the_95percent_confidence_interval = (None, None) # Assign your 95% confidence interval lower and upper bounds\n",
    "# Round to 2 digits of accuracy\n",
    "Q18 = (three_digit_random_nubmer_seed, number_of_bootstrap_sample_repititions, the_95percent_confidence_interval)\n",
    "# E.g. `Q18 = (123, 10000, (0.12, 0.34))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0190c5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m bootstrapped_death_prob \u001b[39m=\u001b[39m data_ones_and_zeros\u001b[39m.\u001b[39moutcome\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     12\u001b[0m \u001b[39m# once again, we do not want to alter the `data_ones_and_zeros` DataFrame\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(num_samples):\n\u001b[0;32m     16\u001b[0m     bootstrapped_death_prob[data_ones_and_zeros\u001b[39m.\u001b[39mgroup\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mairbag\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[0;32m     17\u001b[0m     data_ones_and_zeros\u001b[39m.\u001b[39moutcome[data_ones_and_zeros\u001b[39m.\u001b[39mgroup\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mairbag\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     19\u001b[0m     bootstrapped_death_prob[data_ones_and_zeros\u001b[39m.\u001b[39mgroup\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_airbag\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[0;32m     20\u001b[0m     data_ones_and_zeros\u001b[39m.\u001b[39moutcome[data_ones_and_zeros\u001b[39m.\u001b[39mgroup\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_airbag\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mvalues\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# test_Q18\n",
    "# bootstrap sampling distribution simulation\n",
    "seed, num_samples, interval = Q18\n",
    "\n",
    "np.random.seed(seed)\n",
    "simulated_values = np.array([0.0]*num_samples)\n",
    "\n",
    "data_ones_and_zeros = crash_data.replace({'dead': 1, 'alive': 0})   \n",
    "simdata = data_ones_and_zeros.copy()\n",
    "# may be easier for you to work with 1's and 0's to simplify our propotions\n",
    "\n",
    "bootstrapped_death_prob = data_ones_and_zeros.outcome.values.copy()\n",
    "# once again, we do not want to alter the `data_ones_and_zeros` DataFrame\n",
    "\n",
    "for i in range(num_samples):\n",
    "\n",
    "    # \"no_airbag\" is bootstrapped first then \"airbag\": psuedorandomness results will be different\n",
    "    # if the order is different or if this is done in some other manner...\n",
    "    # this could be what's happening if your confidence is pretty close but numerically different\n",
    "\n",
    "    bootstrapped_death_prob[data_ones_and_zeros.group==\"no_airbag\"] = \\\n",
    "    data_ones_and_zeros.outcome[data_ones_and_zeros.group==\"no_airbag\"].sample(frac=1, replace=True).values\n",
    "    \n",
    "    bootstrapped_death_prob[data_ones_and_zeros.group==\"airbag\"] = \\\n",
    "    data_ones_and_zeros.outcome[data_ones_and_zeros.group==\"airbag\"].sample(frac=1, replace=True).values\n",
    "\n",
    "    simdata['outcome'] = bootstrapped_death_prob\n",
    "\n",
    "    simvalue = np.diff(simdata.groupby('group').mean().values.flatten())[0]\n",
    "    # since dead's are '1' and alive's are '0', the mean() function gets us the proportion of death\n",
    "    # (in each group, summing up the number of deaths and dividing by the number of crashes\n",
    "    # is our caculation for the proportion of deaths, but this is also the calculation for mean!)\n",
    "    simvalue = np.divide(*np.flip(simdata.groupby('group')['outcome'].mean().values.flatten()))\n",
    "    # relative rather than absolute: ratio rather than difference\n",
    "    \n",
    "    simulated_values[i] = simvalue\n",
    "\n",
    "calc_interval = tuple(np.round(np.quantile(simulated_values, (0.025, 0.975)), 2))\n",
    "assert calc_interval == interval, \"You got \" + str(interval) + \" for your 95% confidence interval but should be \" + str(calc_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df85ca3",
   "metadata": {},
   "source": [
    "## Type I and II Errors\n",
    "\n",
    "In the analyses of the previous week and this week you've used a quantiative p-value to provide a qualitative statement of the evidence against the *null hypothesis*. This doesn't necessarily entail a formal decision about a *null hypothesis* (and there are many good reasons to proceed in this manner without doing so). However, it would also be possible to make a formal statement about the *null hypothesis* which should ideally take the form of \"I choose to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand\", or contrarily \"I fail to reject the *null hypothesis*...\" \n",
    " \n",
    "In *formal statstical hypothesis testing*, wrongly rejecting a *null hypothesis* which is actually true is called a *type I error*; whereas, wrongly failing to reject a *null hypothesis* which is actually false is called a *type II error*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137c4f1",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q19: Make a statement about the null hypothesis based on your analysis above in Q17. What kind of error could you have made in your conclusion?\n",
    "A. I choose to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars that have an airbag and those without an airbag is actually the same, then we have made a Type I Error.  \n",
    "\n",
    "B. I choose to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars that have an airbag and those without an airbag is actually the same, then we have made a Type II Error.   \n",
    "\n",
    "C. I fail to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars without an airbag is actually greater than cars with an airbag, then we have made a Type I Error.  \n",
    "\n",
    "D. I fail to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars without an airbag is actually greater than cars with an airbag, then we have made a Type II Error.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cde3b390",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q19: your answer will be tested!\n",
    "Q19 = None # Assign either 'A' or 'B' or 'C' or 'D' to `Q19` instead of `None`\n",
    "# E.g., Q19 = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc330028",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calc_p_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q19\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m hint \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou reported a p-value of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(p_value) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m (correct p-value was \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(calc_p_value) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m hint \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mand correspondingly\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m hint \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcharacterized this the evidence against the null hypothesis as option \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m evidence \n",
      "\u001b[1;31mNameError\u001b[0m: name 'calc_p_value' is not defined"
     ]
    }
   ],
   "source": [
    "# test_Q19\n",
    "\n",
    "hint = \"You reported a p-value of \" + str(p_value) + \" (correct p-value was \" + str(calc_p_value) + \") \"\n",
    "hint += \"and correspondingly\\n\"\n",
    "hint += \"characterized this the evidence against the null hypothesis as option \" + evidence \n",
    "hint += \"\\n(A: NONE; B: WEAK; C: MODERATE; D: STRONG; E: VERY STRONG).\\n\" \n",
    "hint += \"A p-value of \" + str(calc_p_value) + \" corresponds to \" +  evidence_choice_in_words[actually_correct_evidence_choice]\n",
    "hint += \" evidence against the null hypothesis\\n\"\n",
    "hint += \"So your characterization of evidence against the null hypothesis was \"\n",
    "hint += \"incorrect\"*(not evidence_test) + \"correct\"*(evidence_test) + \".\\n\\n\"\n",
    "hint += \"Assuming you did not choose to reject the null hypthesis if the evidence against it\\n\"\n",
    "hint += \"was WEAK or if there was NO evidence against the null hypthesis, then you could have\\n\"\n",
    "hint += \"made a type II error by failing to reject a false null hypothesis.\\n\"\n",
    "hint += \"This was not mean a type II error was made: it just means it could have been made.\\n\\n\"\n",
    "hint += \"Assuming you did choose to reject the null hypthesis if the evidence against it\\n\"\n",
    "hint += \"was MODERATE to VERY STRONG evidence against the null hypthesis, then you could have\\n\"\n",
    "hint += \"made a type I error by rejecting a true null hypothesis.\\n\"\n",
    "hint += \"This was not mean a type I error was made: it just means it could have been made.\"\n",
    "\n",
    "assert ((evidence=='A' or evidence=='B') and Q19 == 'D') or ((evidence!='A' and evidence!='B') and Q19 == 'A'), hint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ba201",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q20: Assuming your analysis has provided some evidence against the null hypothesis of no survival differences in car crashes between cars with and without airbags, are you ready to suggest and support the claim that this data supports the claim that \"airbags save lives\"? Explain how this data could be confounded by either (a) \"death wish\" drivers and (b) age in a manner that could produce the observed survival rate differences and therefore shed doubt on the claim that \"airbags save lives\" and discuss wheather or not you find entertaining each of these two possibilites compelling.\n",
    "\n",
    "> - Hint: In the \"Social Media and Anxiety\" problem we imagined that people who were already prone to anxiety might also be more likely to use social media with a higher frequency. What would be a story about (a) \"death wish drivers\" and (b) \"age\" that could cause people to both tend to drive cars without airbags and be more likely die in a car crash?\n",
    "\n",
    "#### Provide your written answer about four to six sentences in the markdown cell below.  \n",
    "- This will be manually reviewed by your TA.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b5e8d",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f8713",
   "metadata": {},
   "source": [
    "#### SAMPLE SOLUTION for TAs to share with poor solution answers\n",
    "\n",
    "The data does indeed appear to support the claim that \"airbags save lives\". \n",
    "But, a \"death wish\" driver intentionally choosing to drive a car without airbags while trying to get into a bad wreck in order to die would also seem to empirically support this claim if we didn't know the intentions of such a driver. It does seems unlikely, thought, that there would be a lot of \"death wish\" drivers skewing the data in this manner.\n",
    "However, if older people tend to drive cars without airbags because they have older cars, and if because they're older they're potentially more frail and more prone to die as a result of injuries, then this confounding could also make it appear as if \"airbags save lives\" when in fact the reason for the observed difference was not due to increased protection from airbags and instead just a result of this age confounding by. \n",
    "For this to be a compelling argument, we'd have to examine crash death rates by age, and we'd have to see if there are a large proportion of older people that could be imbalanced between driving cars with and without airbags. It seems, though, that the nature of the confounding that would cause such an effect would need to be pretty strong in order to account for the differences we're seeing without any positive safety effect of seatbelts themselves... so perhaps it is unlikely.  However, it does seem like something that could and should be checked with additional data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a68be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 6
}
