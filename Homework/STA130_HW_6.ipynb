{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa1e99a5",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Coding Homework 6: [Your Name]\n",
    "\n",
    "Go through this notebook, following the instructions! \n",
    "\n",
    "- You can add new cells if you need (with the \\\"+\\\" button above); but, deleting cells could very likely cause your notebook to fail MarkUs autotesting (and you'd have to start over and re-enter your answers into a completely fresh version of the notebook to get things to work again...)\n",
    "\n",
    "> TAs will mark this assignment by first checking ***MarkUs*** autotests for completion and general correctness, and then manually reviewing your written response to `Q16` and `Q20` and quickly double checking for the presense of plotted figures for `Q2`, `Q17` and `Q18`.\n",
    "> - The  `Q0, Q2, Q4, Q16` questions \"automatically fail\" during automated testing so that MarkUs exposes example answers for student review and consideration for these problems: these \"failed MarkUs tests\" are not counted against the student.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb0423",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Social Media and Anxiety\n",
    "\n",
    "There have been many questions regarding whether or not social media usage increases anxiety levels. For example, do  TikTok and Facebook posts create an unattainable sense of life success and satisfaction?  Does procrastinating by watching YouTube videos or reading Twitter posts contribute unnecessary stress from deadline pressure? A study was conducted to examine the relationship between social media usage and student anxiety. Students were asked to categorize their social media usage as \"High\" if it exceeded more than 2 hours per day, and then student anxiety levels where scored through as series of questions, with higher scores suggesting higher student anxiety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc11e2",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# The `numpy.repeat` function replicates elements as demonstrated here\n",
    "social_media_usage = np.repeat([\"Low\", \"High\"], [30, 16])\n",
    "anxiety_scores = [24.64, 39.29, 16.32, 32.83, 28.02, \n",
    "                   33.31, 20.60, 21.13, 26.69, 28.90,\n",
    "                   26.43, 24.23, 7.10,  32.86, 21.06,\n",
    "                   28.89, 28.71, 31.73, 30.02, 21.96,\n",
    "                   25.49, 38.81, 27.85, 30.29, 30.72,\n",
    "                   21.43, 22.24, 11.12, 30.86, 19.92,\n",
    "                   33.57, 34.09, 27.63, 31.26,\n",
    "                   35.91, 26.68, 29.49, 35.32,\n",
    "                   26.24, 32.34, 31.34, 33.53,\n",
    "                   27.62, 42.91, 30.20, 32.54]\n",
    "anxiety_data = pd.DataFrame({'anxiety_scores': anxiety_scores, 'social_media_usage': social_media_usage})\n",
    "anxiety_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7e5b9",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q0: In simple terms, what is the claim of the *null hypothesis* for the experiment above that we are naturally trying to provide evidence against? How could this be formally stated with respect to the parameters $Median_{High}$ and $Median_{Low}$ of the two populations in question? And what is $H_1$ in terms of $H_0$?\n",
    "\n",
    "#### Provide your written answer in the markdown cell below.\n",
    "- You can compare your answer with the example solution provided by MarkUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e73e0",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Hint: In two-sample contexts the *null hypotheses* tends to be the most natural form of a \"no effect\" statement that \"nothing interesting or notable is happening\"; and, it's generally a \"straw man\" that we're trying to provide enough evidence against to reject. For example, a formal *null hypotheses* that there is no difference in the means of two groups would be $H_0: \\mu_{High} = \\mu_{Low}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af87b2b",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf8950",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q1: Revisit your statements regarding the *null hypotheses* above with \"confounding\" in mind; namely, since social media usage is a self-selecting process, perhaps social media users are already more anxious people on average regardless of their social media usage.  If we provide evidence about the *null hypotheses* are we actually addressing the question of \"whether or not usage of social media increases anxiety levels\"? Or are we just using a hypothesis test to examine if there is strong evidence of difference between the two groups (regardless of its causes)?  \n",
    "\n",
    "A. Neither, we are checking if confounding impacts our determination of \"whether or not usage of social media increases anxiety levels\"  \n",
    "B. We actually addressing the question of \"whether or not usage of social media increases anxiety levels\"   \n",
    "C. We are just using a hypothesis test to examine how strong the observable evidence of a difference between the two groups is (regardless of its causes)  \n",
    "D. None of the above: we cannot determine any of the above from a two-sample hypothesis test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef4a6a6",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q1: your answer will be tested!\n",
    "Q1 = None  # Assign either 'A' or 'B' or 'C' or 'D' to `Q1` instead of `None`\n",
    "# E.g., Q1 = 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6a5b2",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q2: Construct boxplots of `anxiety_score` for the two levels of social media usage, and write 2-3 sentences describing and comparing the distributions of anxiety scores across the social media usage groups.  \n",
    "#### Provide your written answer in the markdown cell below.\n",
    "- You can compare your answer with the example solution provided by MarkUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8211ff",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Code your solution here\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae8370",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d71493",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q3: What do these data visually suggest regarding the claim that the ***median*** anxiety level is different for the population of people with high frequency social media use compared to the population with low frequency use? \n",
    "\n",
    "A. The median anxiety level is likely higher for low frequency social media users compared to higher frequency social media users.  \n",
    "B. We cannot say, since the groups are shuffled and we do not know the proportion of high frequency or lower frequency social media users in each group.    \n",
    "C. The median anxiety level is likely the same for low frequency social media users compared to higher frequency social media users.  \n",
    "D. The median anxiety level is likely higher for high frequency social media users compared to lower frequency social media users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21826f8b",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q3: your answer will be tested!\n",
    "Q3 = None  # Assign either 'A' or 'B' or 'C' or 'D' to `Q3` instead of `None`\n",
    "# E.g., Q3 = 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c551c2",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q4: Write a few sentences explaining what the code inside the `for` loop below does and why it's doing it.  \n",
    "#### Provide your written answer in the markdown cell below.\n",
    "- You can compare your answer with the example solution provided by MarkUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08324cb1",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3fa41",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "observed_test_statistic = np.diff(anxiety_data.groupby('social_media_usage').median().values.flatten())\n",
    "\n",
    "np.random.seed(1) # make the simulation reproducible...\n",
    "repetitions = 1000 \n",
    "irrelevant_labels_null_hypothesis_simulated_values = []\n",
    "\n",
    "shuffled_anxiety_data = anxiety_data.copy() # you should essentially always use `.copy()` for data frames; otherwise,\n",
    "# changes to the new data frame will also appear in the original version of the data frame as well(!)\n",
    "\n",
    "for i in range(repetitions):\n",
    "    shuffled_anxiety_data['social_media_usage'] = anxiety_data['social_media_usage'].sample(frac=1).values\n",
    "    permutation_statistic = np.diff(shuffled_anxiety_data.groupby('social_media_usage').median().values.flatten())[0]\n",
    "    irrelevant_labels_null_hypothesis_simulated_values += [permutation_statistic]\n",
    "\n",
    "fig = px.histogram(pd.DataFrame({'Difference in Medians': irrelevant_labels_null_hypothesis_simulated_values}), \n",
    "                   x='Difference in Medians', color_discrete_sequence=['grey'])\n",
    "fig.update_traces(marker_line_width=1, marker_line_color=\"black\")\n",
    "fig.add_vline(x=observed_test_statistic[0], line_width=3, line_dash=\"dash\", line_color=\"red\")\n",
    "fig.add_vline(x=abs(observed_test_statistic[0]), line_width=3, line_dash=\"dash\", line_color=\"red\")\n",
    "fig.show()\n",
    "\n",
    "num_as_or_more_extreme = (abs(np.array(irrelevant_labels_null_hypothesis_simulated_values)) >= \n",
    "                          abs(observed_test_statistic)).sum()\n",
    "p_value = num_as_or_more_extreme / repetitions\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002c359",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q5: Which statement below best states the evidence you have against the *null hypothesis* based on the simulated p-value above?\n",
    "A. `0.10 < p-value`: No evidence against the null hypothesis  \n",
    "B. `0.05 < p-value <= 0.10`: Weak evidence against the null hypothesis  \n",
    "C. `0.01 < p-value <= 0.05`: Moderate evidence against the null hypothesis  \n",
    "D. `0.001 < p-value <= 0.01`: Strong evidence against the null hypothesis  \n",
    "E. `p-value < 0.001`: Very strong evidence against the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678adfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: your answer will be tested!\n",
    "Q5 = None # Assign either 'A' or 'B' or 'C' or 'D' or 'E' to `Q5` instead of `None`\n",
    "# E.g., Q5 = 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abcc58f",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q6: Does this data support the claim that the ***median*** anxiety level is different for those who use social media in high frequency compared to those who use social media in lower frequency?  How about the claim that \"usage of social media increases anxiety levels\"?\n",
    "\n",
    "A. Yes to the first, and yes to the second... there is a difference in median anxiety levels for those who use social media in high frequency compared to those who use social media in lower frequency, and it is because social media increases anxiety levels\n",
    "\n",
    "B. Yes to the first; but, no to the second... it seems possible -- not saying it's true, just plausible -- that different predispositions to anxiety could also have different predispositions to social media usage.  \n",
    "\n",
    "C. No to the first, and no to the second... this data does not adequately support the claim that the median anxiety level is different for those who use social media in high frequency compared to those who use social media in lower frequency  \n",
    "\n",
    "D. No to the first; but, yes to the second... the claim that the median anxiety level is different for those who use social media in high frequency compared to those who use social media in lower frequency is not supported, but we know usage of social media increases anxiety levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363f3f8",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q6: your answer will be tested!\n",
    "Q6 = None # Assign either 'A' or 'B' or 'C' or 'D' to `Q6` instead of `None`\n",
    "# E.g., Q6 = 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a7066",
   "metadata": {},
   "source": [
    "### Q7: Use `scipy.stats.median_test` to calculate a p-value which could be used to provide evidence of a difference between the two social media usage groups.\n",
    "\n",
    "#### Provide your answer rounded to 3 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dabc6d",
   "metadata": {},
   "source": [
    "> - Hint 1: The \"median test\" produces a nonparametric p-value under the null hypothesis assumption that the median of two populations (here median anxiety levels of \"High\" and \"Low\" social media usage populations) are the same.\n",
    "> \n",
    "> ```python\n",
    "> from scipy import stats \n",
    "> stats.median_test(series_A, series_B)\n",
    "> # where `series_A` and `series_B` are your two samples\n",
    "> ```\n",
    "> \n",
    "> - Hint 2: Use the `numpy.round` function to round your calculation.\n",
    ">\n",
    "> - Hint 3: The \"median test\" is nonparametric just like the permutation test p-value simulate above; however, they are not quite the same test because they are based on slightly different assumptions. Notice how the null hypothesis assumptions between the two are slighly different: \n",
    ">   - Shuffling the labels assumes that the labels don't matter, which implies that there's no difference between the populations the two samples come from; which, is a very strong statement null hypothesis (and we generally might expect stronger assumptions to be helpful in producing slightly small p-values...).\n",
    ">   - The \"median test\" instead is just based on assuming if the medians of the two populations are the the same, then the null hypothesis should be that half of the observations in the first group should be larger than half of the observations in the second group, and vice-versa; which, can be used to contruct another test based on the Binomial distribution in a manner that is very much analagously to how such a Binomial test was created for a one-sample context...\n",
    ">     - Since the assumption of the \"median test\" is a little simpler and weaker than assuming two populations are identical and their samples interchangable, we'd expect p-values from a \"median test\" to be a little larger than p-values from a test based on a null hypothesis with slightly stronger assumptions...\n",
    ">     - Nonparametric p-values tend be a little bit larger than their parametric counterparts exactly because nonparametric null hypotheses tend to make fewer assumptions regarding the populations they're testing than their parametric counterparts which need to rely upon assumptions about the populations producing the samples being analyzed...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49c9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# space for your work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: your answer will be tested!\n",
    "Q7 = None  # Assign p-value rounded to 3 decimal places to Q7 instead of 'None'\n",
    "# E.g., Q7 = '0.987'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a57f4",
   "metadata": {},
   "source": [
    "### Q8: Is the \"median test\" a parametric or non-parametric test and why?\n",
    "\n",
    "A. Parametric since the assumption that the population medians are equal implies that each population is normally distributed  \n",
    "B. Parametric since the boxplots of the data and histogram of the sampling distribution appears to be normally distributed  \n",
    "C. Nonparametric since a sample can never be normally distributed  \n",
    "D. Nonparametric since it makes no distributional assumptions (such as normality) about either of the population  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: your answer will be tested!\n",
    "Q8 = None  # Assign either 'A' or 'B' or 'C' or 'D' to `Q8` instead of `None`\n",
    "# E.g., Q8 = 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede7d590",
   "metadata": {},
   "source": [
    "### Q9: Use `scipy.stats.mannwhitneyu` to calculate a p-value which could be used to provide evidence of a difference between the two social media usage groups.\n",
    "\n",
    "#### Provide your answer rounded to 3 decimal places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406d4e1",
   "metadata": {},
   "source": [
    "> - Hint 1: the \"Mann-Whitney U test\" is based on a null hypothesis that assumes there is \"no actual distributional difference between two populations\" (here \"High\" and \"Low\" social media usage populations). \n",
    "> ```python\n",
    "> stats.mannwhitneyu(series_A, series_B)\n",
    "> # where `series_A` and `series_B` are your two samples\n",
    "> # Do not use `scipy.stats.wilcoxon`... that's for \"paired\" samples \n",
    "> # with one-to-one pairing of observations...\n",
    "> ```\n",
    "> - Hint 2: The \"Mann-Whitney U test\" is based on a null hypothesis that uses a stronger assumption compared to the median test that is identical to the assumption of the permutation test used to produce the initially simulated p-value; however, there is a slight difference in the observed test statistic used by the \"Mann-Whitney U test\" compared to the observed difference of medians used in the permutation test...\n",
    ">   - Using the assumption of \"no actual distributional difference between two populations\" implies that if all observations are \"ranked\" smallest to largest, the sum of the ranks should end up the same on average. This, however, means the \"Mann-Whitney U test\" will produce its p-value based on all the data (ranks totalling equivalently) as opposed to just considering the difference between the medians in two samples.  Making a p-value based on all the relative ranks of the samples will of course be more informative than just the medians of samples; so, even though the base assumption of the \"Mann-Whitney U test\" null hypothesis is the same as the permutation test, the data is used in a more powerful manner in the \"Mann-Whitney U test\"...\n",
    "> - Hint 3: The \"Mann-Whitney U test\" is a two sample test that is (of coures) distinct from the \"Wilcoxon Rank Sum test\" (`scipy.stats.wilcoxon`). The former is for two samples where the observations don't come in pairs; whereas, the latter is for when there are two samples but the observations have a natural pairing with each other.\n",
    ">    - Our samples don't involve having measurements on twins or something like that, so the our samples don't naturally come in pairs...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee764049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for your work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a301d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9: your answer will be tested!\n",
    "Q9 = None  # Assign p-value rounded to 3 decimal places to Q9 instead of 'None'\n",
    "# E.g., Q9 = '0.987'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba568ffc",
   "metadata": {},
   "source": [
    "### Q10: Is the \"Mann-Whitney U test\" a parametric or non-parametric test and why?\n",
    "\n",
    "A. Parametric since the assumption of \"no actual difference between groups\" can only occur if each population is normally distributed   \n",
    "B. Parametric since the boxplots of the data and histogram of the sampling distribution appears to be normally distributed  \n",
    "C. Nonparametric since the two populations might not be normally distributed  \n",
    "D. Nonparametric since the two populations have different distributions and so only one can be normally distributed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d01c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10: your answer will be tested!\n",
    "Q10 = None  # Assign either 'A' or 'B' or 'C' or 'D' to `Q10` instead of `None`\n",
    "# E.g., Q10 = 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8cbd1a",
   "metadata": {},
   "source": [
    "### Q11: Use `scipy.stats.ttest_ind` to calculate a p-value which could be used to provide evidence of a difference between the two social media usage groups.\n",
    "\n",
    "#### Provide your answer rounded to 3 decimal places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f6fee",
   "metadata": {},
   "source": [
    "> - Hint 1: The \"two-sample t-test\" has a null hypothesis that assumes the means of two populations (here mean anxiety levels of \"High\" and \"Low\" social media usage populations) are equal and that the samples are drawn from normally distributed populations.\n",
    "> ```python\n",
    "> stats.ttest_ind(series_A, series_B, equal_var=False)\n",
    "> # where `series_A` and `series_B` are your two samples\n",
    "> # Do not use `stats.ttest_rel`... that's for \"paired\" samples \n",
    "> # with one-to-one pairing of observations...\n",
    "> ```\n",
    "> - Hint 2: a mean is of course distinct from a median, generally speaking; however, the mean and median are the same for a population that is symmetric such as a normally distributed population; thus, the assumption of the null hypothesis that the distributions are normally disributed and have the same means here implies that they have the same medians...\n",
    "> - Hint 3: when doing a twosample t-test it is possible to make assumptions about the two normal populations under examination, such as if the variances (or equivalently the standard deviations) of the two populations are the same or not. By default `stats.ttest_ind` uses `equal_var=True`; but, given the observed boxplots of these two distributions, it seems like `equal_var=False` is a better assumption for this test; so, that's what you should use here as in the example code above...\n",
    "> - Hint 4: there is another function `stats.ttest_rel` which is (of course) distinct from `stats.ttest_ind`. The difference between these is analagous to the difference between the \"Wilcoxon Rank Sum test\" (`scipy.stats.wilcoxon`) and the \"Mann-Whitney U test\" (`scipy.stats.mannwhitneyu`); namely, the former is for when the observations have a natural pairing with each other, while the latter is when the observations don't come in pairs.\n",
    ">    - Our samples don't involve having measurements on twins or something like that, so the our samples don't naturally come in pairs...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcec329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for your work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140593d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11: your answer will be tested!\n",
    "Q11 = None  # Assign p-value rounded to 3 decimal places to Q11 instead of 'None'\n",
    "# E.g., Q11 = '0.987'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d699173e",
   "metadata": {},
   "source": [
    "### Q12: Is the \"two-sample t-test\" a parametric or non-parametric test and why?\n",
    "\n",
    "A. Parametric since we assume samples are drawn from normally distributed populations  \n",
    "B. Parametric since the boxplots of the data and histogram of the sampling distribution appears to be normally distributed  \n",
    "C. Nonparametric since the assumption that the means for each group being equal does not imply that the populations are normally distributed  \n",
    "D. Nonparametric since a sample can never be normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q12: your answer will be tested!\n",
    "Q12 = None  # Assign either 'A' or 'B' or 'C' or 'D' to `Q12` instead of `None`\n",
    "# E.g., Q12 = 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ac2ac",
   "metadata": {},
   "source": [
    "### Q13: Give the strength of evidence against the null hypothesis for the three tests considered above.\n",
    "\n",
    "1. \"Median test\" which specifies a null hypothesis that assumes the medians of the two populations are equal\n",
    "2. \"Mann-Whitney U test\" which specifies a null hypothesis that assumes the two populations are identical\n",
    "3. \"Two-sample t-test\" which specifies a null hypothesis that assumes the two populations are normally distributed with the same means<br>(but different standard deviations, for the specification above)\n",
    "\n",
    "A. `0.10 < p-value`: No evidence against the null hypothesis  \n",
    "B. `0.05 < p-value <= 0.10`: Weak evidence against the null hypothesis  \n",
    "C. `0.01 < p-value <= 0.05`: Moderate evidence against the null hypothesis  \n",
    "D. `0.001 <= p-value <= 0.01`: Strong evidence against the null hypothesis  \n",
    "E. `p-value < 0.001`: Very strong evidence against the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f5275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13: your answer will be tested!\n",
    "Q13 = (None,None,None) # Assign a triple tuple comprised of 'A's, 'B's, 'C's, 'D's and/or 'E' to `Q13`\n",
    "# instead of the `None` triple tuple `(None,None,None)` in the order of Median test, Mann-Whitney U test\n",
    "# and Two-sample t-test\n",
    "# E.g., Q13 = ('A','B','C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86716ca6",
   "metadata": {},
   "source": [
    "### Q14: Relative to the p-value calculations based on `scipy.stats.ttest_1samp` and `scipy.stats.binom` from the homework exercise of the previous week. Which of the following is correct?\n",
    "\n",
    "A. The `stats.ttest_1samp` and `stats.binom` methods **theoretically** derive p-value under their null hypothesis, while `stats.median_test`, `stats.mannwhitneyu`, and `stats.ttest_ind` do not  \n",
    "\n",
    "B. The `stats.ttest_1samp` and `stats.ttest_ind` methods use continuous approximations of the theoretical binomial sampling distribution of the `stats.binom` and `stats.median_test` and `stats.mannwhitneyu` methods, respectively, which is why these t-tests produce nonparametric p-values  \n",
    "\n",
    "C. The `stats.ttest_1samp`, `stats.ttest_ind`, and `stats.ttest_rel` are parametric due to their assumption regarding the normally distributed nature of the populations they consider; whereas, `stats.binom`, `stats.median_test`, `stats.mannwhitneyu`, and `stats.wilcoxon` based methods are nonparametric since they rely on no specific distributional assumptions such as population normality. \n",
    "\n",
    "D. The `stats.ttest_1samp` and `stats.binom` most closely related to `stats.ttest_ind` (rather than `stats.ttest_rel`) and `stats.mannwhitneyu` and `stats.wilcoxon` (rather than `stats.median_test`), respectively.  \n",
    "\n",
    "E. `stats.ttest_1samp` and `stats.binom` are only good for 50/50 chance problems; so, `stats.median_test`, `stats.mannwhitneyu`, and `stats.ttest_ind` exist in order to consider different comparision populations.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c22e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint 1:\n",
    "print((1-stats.binom(n=100, p=0.5).cdf(60-1))*2)\n",
    "# Probability of getting a combination more as or extreme than 60 heads in 100 coin flips for a 50-50 coin\n",
    "\n",
    "# Hint 2:\n",
    "coin_flips = [1] * 60 + [0] * 40  # 1 for head, 0 for tails\n",
    "stats.ttest_1samp(coin_flips, 0.5) \n",
    "# Probability of getting a combination as or more extreme than 60 heads in 100 coin flips for a 50-50 coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14: your answer will be tested!\n",
    "Q14 = None  # Assign either 'A', 'B', 'C', 'D', or 'E' to `Q14` instead of `None`\n",
    "# E.g., Q14 = 'A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7a873",
   "metadata": {},
   "source": [
    "### Q15: Create a 90% bootstrap confidence interval estimating the difference in median anxiety scores between the social media usage groups. \n",
    "\n",
    "#### Provide your interval endpoint answers rounded to 3 decimal places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72513439",
   "metadata": {},
   "source": [
    "> - Hint 1: The process within the `for` loop in `Q4` is not quite right since it's based on the assumption of a null hypothesis that the labels don't matter; however, when making a confidence interval we do think the labels matter! So, the `for` loop for a confidence interval should instead provide a simulation producing repeated pairs of bootstrap samples which can then be used to create simulated median difference test statistic that are samples from the bootrapped sampling distribution of the difference in medians...  \n",
    "> - Hint 2: Don't forget about the `np.quantile()` function...\n",
    "> - Hint 3: Be careful that you haven't accidentally overwritten the values in `anxiety_data.anxiety_scores`...\n",
    ">   - Working instead with something like `simdata = anxiety_data.copy()` and `bootstrapped_anxiety_scores = anxiety_data.anxiety_scores.values.copy()` would help protect against this... and you can tell pretty quickly that you might be making this mistake if your simulated median difference statistics are all the same value!\n",
    "> - Hint 4: code like the following\n",
    ">   ```python\n",
    ">   simdata['anxiety_scores'][anxiety_data.social_media_usage==\"Low\"] = \\\n",
    ">      anxiety_data['anxiety_scores'][anxiety_data.social_media_usage==\"Low\"].\\\n",
    ">        sample(frac=1, replace=True).values\n",
    ">   ```\n",
    ">   will produce a\n",
    ">\n",
    ">   `SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame`  \n",
    ">\n",
    ">   because `simdata['anxiety_scores'][anxiety_data.social_media_usage==\"Low\"]` is itself a \"slice\" of a `pd.DataFrame` even if `simdata = anxiety_data.copy()`; so, instead, sequentially assign into something like \n",
    ">   - `bootstrapped_anxiety_scores = anxiety_data.anxiety_scores.values.copy()` \n",
    ">     - `bootstrapped_anxiety_scores[anxiety_data.social_media_usage==\"Low\"] = ...`\n",
    ">     - `bootstrapped_anxiety_scores[anxiety_data.social_media_usage==\"High\"] = ...`\n",
    ">   - and finally `simdata['anxiety_scores'] = bootstrapped_anxiety_scores` without any \"slice\" usage in order to use \n",
    ">   - `np.diff(simdata.groupby('social_media_usage').median().values.flatten())[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4057fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for scratch work if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the following line at the top! And, replace `None` below with the three digit integer \n",
    "np.random.seed(None) # made from the 1st, 3rd, and 5th digits or your student number. \n",
    "\n",
    "# Code your bootstrap sampling distribution simulation here... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10fa7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_digit_random_nubmer_seed = None \n",
    "# Match the integer created from the 1st, 3rd, and 5th digits of your student number used above...\n",
    "# your results must be based on this random number seed so that they can be confirmed during autotesting\n",
    "number_of_bootstrap_sample_repititions = None # number of simulated median difference test statistics\n",
    "# sampled from the bootstrapped sampling distribution of the difference in medians\n",
    "the_90percent_confidence_interval = (None, None) # Assign your 90% confidence interval lower and upper bounds\n",
    "# Round to 3 digits of accuracy\n",
    "Q15 = (three_digit_random_nubmer_seed, number_of_bootstrap_sample_repititions, the_90percent_confidence_interval)\n",
    "# E.g. `Q15 = (123, 10000, (0.123, 0.456))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a870f5",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Airbags\n",
    "The table below is adapted from a \"Biostatistics for the Biological and Health Sciences\" textbook example and presents data from a random sample of passengers sitting in the front seat of cars involved in car crashes. Based on this data we'd like to make a determination as to whether or not death rates differ for passengers in cars with airbags and passengers in cars without airbags.\n",
    "\n",
    "|                           | Airbag available | No airbag available |\n",
    "|---------------------------|------------------|---------------------|                           \n",
    "| Passenger Fatalities      |  45              | 62                  |\n",
    "| Total number of Passengers|  10,541          | 9,867               |\n",
    "\n",
    "- The code below creates a pandas data frame for this problem with the help of the `numpy.repeat` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2b718",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "crash_data = pd.DataFrame({'group': np.repeat([\"airbag\", \"no_airbag\"], [10541, 9867]), \n",
    "                           'outcome': np.repeat([\"dead\", \"alive\", \"dead\", \"alive\"], [45, 10541-45, 62, 9867-62])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50ade0",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q16: In simple terms, state the claim of the *null hypothesis* for the context above that we are naturally trying to provide evidence against.  State this formally in terms of the two population parameters probabilities of death $p_{airbag}$ and $p_{no-airbag}$ in question. Finally, formally state the *alternative hypothesis* $H_1$ that makes this a *one-sided hypothesis test* such that (during the p-value calculation process) \"as or more extreme\" only considers evidence indicating that survival rates are strictly better in cars with airbags. \n",
    "\n",
    "> - Hint 1: Formulate the null and alternative hypotheses in the request 'one-sided' manner (as opposed to as a 'two-sided' specification) by using using a less than $<$ sign as opposed to the typical \"$H_1: H_0\\text{ is false}$\".  Doing so indicates that there is no evidence against the null hypothesis if the survival rates are worse for cars with airbags; but, on the other hand, this actually tends to reduce p-values by a factor of two since it means only check \"as or more extreme\" on one side (\"better than\" direction only) of the sampling distribution implied by the null hypothesis.\n",
    "> \n",
    "> - Hint 2: In the previous \"Social Media and Anxiety\" example it was suggested that it might be plausible for there to be a pre-existing association between anxiety and the choice to use social media more frequently. In this case, does it feel similarly possible that people who are more likely to die in a car crash (for whatever reason) would also be people who would choose to drive a car without an airbag? It feels like an argument of some kind of \"confounding\" affecting things here might be less likely than anxious people using more social media; but, what kind of story could you tell which might in fact produce \"confounding\" in the current car crash surival context? \n",
    "\n",
    "#### Provide your written answer in the markdown cell below.\n",
    "- The TA will manually review and confirm the correctness of your submitted answer for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3418eb",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0741b",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q17: Use \"label shuffling\" to simulate and visualize the sampling distribution of the test statistic of the difference between $\\hat p_{no-airbag}$ and $\\hat p_{airbag}$ under the assumption that the *null hypothesis* stated in the previous question is true; and, then compute a \"permutation test\" p-value of the observed test statistic relative to this simulated sampling distribution and indicate the strength of evidence provided against the null hypothesis based on this p-value.\n",
    "\n",
    "A. `0.10 < p-value`: No evidence against the null hypothesis  \n",
    "B. `0.05 < p-value <= 0.10`: Weak evidence against the null hypothesis  \n",
    "C. `0.01 < p-value <= 0.05`: Moderate evidence against the null hypothesis  \n",
    "D. `0.001 < p-value <= 0.01`: Strong evidence against the null hypothesis  \n",
    "E. `p-value <= 0.001`: Very strong evidence against the null hypothesis\n",
    "\n",
    "> - Hint 1: The assumption that the *null hypothesis* stated in the previous question is true implies that the two samples must come from identical populations (with identical survivial proportions); thus, a permutation test p-value similar to the one computed in Q4 is an appropriate nonparametric p-value for this context. \n",
    "> - Hint 2: of course we could also choose to use the alternative methods form computing p-values that we've encountered above; but, for this question please create a \"permutation test\" p-value in order to practice this kind of simulation test. \n",
    "> - Hint 3: you could consider using something like `data.replace({'dead': 1, 'alive': 0})` to replace 'dead' and 'alive' outcomes with 1's and 0's, which might simplify working with proportions slightly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for scratch work if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74111033",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Keep the following line at the top! And, replace `None` below with the three digit integer \n",
    "np.random.seed(None) # made from the 1st, 3rd, and 5th digits or your student number. \n",
    "\n",
    "# Code your permutation test simulation here... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dff4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_digit_random_nubmer_seed = None\n",
    "# Match the integer created from the 1st, 3rd, and 5th digits of your student number used above...\n",
    "# your results must be based on this random number seed so that they can be confirmed during autotesting\n",
    "number_of_bootstrap_sample_repititions = None # number of simulated difference test statistics\n",
    "# drawn from the sampling distribution of the null hypothesis used to calculate your p-value\n",
    "permutation_p_value = None # Assign to p_value your calculated p-value rounded to 3 decimal places\n",
    "# Round to 3 digits of accuracy\n",
    "strength_of_evidence_against_H0 = None # Assign either 'A' or 'B' or 'C' or 'D' or 'E' instead of `None`\n",
    "# E.g., strength_of_evidence_against_H0 = 'A'\n",
    "\n",
    "Q17 = (three_digit_random_nubmer_seed, number_of_bootstrap_sample_repititions, \n",
    "       permutation_p_value, strength_of_evidence_against_H0)\n",
    "# E.g. `Q17 = (123, 10000, 0.123, 'A')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6da9829",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q18: Create a 95% bootstrap confidence interval estimating the difference in probability of death ($p_{airbag}$ and $p_{no-airbag})$ between passengers in cars with airbags and passengers in cars without airbags. Then visualize the distribution of the bootstrapped sample proportion differences.\n",
    "\n",
    "#### Provide your interval endpoint answers rounded to 5 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c836d7",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# space for scratch work if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the following line at the top! And, replace `None` below with the three digit integer \n",
    "np.random.seed(None) # made from the 1st, 3rd, and 5th digits or your student number. \n",
    "\n",
    "# Code your bootstrap sampling distribution simulation here... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of the bootstrapped sample proportion differences here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3222d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_digit_random_nubmer_seed = None\n",
    "# Match the integer created from the 1st, 3rd, and 5th digits of your student number used above...\n",
    "# your results must be based on this random number seed so that they can be confirmed during autotesting\n",
    "number_of_bootstrap_sample_repititions = None # number of simulated proportion difference test statistics\n",
    "# sampled from the bootstrapped sampling distribution of the difference in death proportions\n",
    "the_95percent_confidence_interval = (None, None) # Assign your 95% confidence interval lower and upper bounds\n",
    "# Round to 5 digits of accuracy\n",
    "Q18 = (three_digit_random_nubmer_seed, number_of_bootstrap_sample_repititions, the_95percent_confidence_interval)\n",
    "# E.g. `Q18 = (123, 10000, (0.12345, 0.45678))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df85ca3",
   "metadata": {},
   "source": [
    "## Type I and II Errors\n",
    "\n",
    "In the analyses of the previous week and this week you've used a quantiative p-value to provide a qualitative statement of the evidence against the *null hypothesis*. This doesn't necessarily entail a formal decision about a *null hypothesis* (and there are many good reasons to proceed in this manner). However, it would also be possible to make a statement about the *null hypothesis* which should ideally take the form of \"I choose to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand\", or contrarily \"I fail to reject the *null hypothesis*...\" \n",
    " \n",
    "In *formal statstical hypothesis testing*, wrongly rejecting a *null hypothesis* which is actually true is called a *type I error*; whereas, wrongly failing to reject a *null hypothesis* which is actually false is called a *type II error*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137c4f1",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q19: Make a statement about the null hypothesis based on your analysis above in Q17. What kind of error could you have made in your conclusion?\n",
    "A. I choose to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars with 'airbag' and with 'no-airbag' is actually the same, then we have made a Type I Error.  \n",
    "\n",
    "B. I choose to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars with 'airbag' and with 'no-airbag' is actually the same, then we have made a Type II Error.   \n",
    "\n",
    "C. I fail to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars with 'no-airbag' is actually more than cars with an 'airbag', then we have made a Type I Error.  \n",
    "\n",
    "D. I fail to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars with 'no-airbag' is actually more than cars with an 'airbag', then we have made a Type II Error.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3b390",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q19: your answer will be tested!\n",
    "Q19 = None # Assign either 'A' or 'B' or 'C' or 'D' to `Q19` instead of `None`\n",
    "# E.g., Q19 = A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ba201",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q20: Assuming your analysis has provided some evidence against the null hypothesis of no survival differences in car crashes between cars with and without airbags, are you ready to suggest and support the claim that this data supports the claim that \"airbags save lives\"? Explain how this data could be confounded by either (a) \"death wish\" drivers and (b) age in a manner that could produce the observed survival rate differences and therefore shed doubt on the claim that \"airbags save lives\" and discuss wheather or not you find entertaining each of these two possibilites compelling.\n",
    "\n",
    "> - Hint: In the \"Social Media and Anxiety\" problem we imagined that people who were already prone to anxiety might also be more likely to use social media with a higher frequency. What would be a story about (a) \"death wish drivers\" and (b) \"age\" that could cause people to both tend to drive cars without airbags and be more likely die in a car crash?\n",
    "\n",
    "#### Provide your written answer about four to six sentences in the markdown cell below.  \n",
    "- This will be manually reviewed by your TA.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b5e8d",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 6
}
